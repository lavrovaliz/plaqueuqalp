{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plaq-u-net: multi-patch consensus U-Net for automated detection and segmentation of the carotid arteries on black blood MRI sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E. Lavrova, 2022\n",
    "\n",
    "This is a code supporting the corresponding paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\E.Lavrova\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "import pydicom\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import cv2\n",
    "import SimpleITK as sitk\n",
    "\n",
    "from skimage import exposure\n",
    "from skimage import img_as_float\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from skimage import morphology\n",
    "from skimage.filters import threshold_otsu, threshold_local\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from scipy.ndimage import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0722 13:25:15.134429 38892 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0722 13:25:15.137429 38892 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0722 13:25:15.139430 38892 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0722 13:25:20.696840 38892 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0',\n",
       " '/job:localhost/replica:0/task:0/device:GPU:1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '4,7'                        \n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def get_unet(input_img, n_filters = 8, dropout = 0.2, batchnorm = True):\n",
    "    \"\"\"Function to define the UNET Model\"\"\"\n",
    "    # Contracting Path\n",
    "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "\n",
    "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    # Expansive Path\n",
    "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    smooth=1\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    from keras.losses import binary_crossentropy\n",
    "    return 0.5*keras.losses.binary_crossentropy(y_true,y_pred)+0.5*dice_loss(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models compilation + loading weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 13:25:28.973867 38892 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0722 13:25:28.980867 38892 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0722 13:25:28.983871 38892 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0722 13:25:29.016867 38892 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0722 13:25:29.064874 38892 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0722 13:25:29.161651 38892 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0722 13:25:29.184652 38892 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0722 13:25:29.857954 38892 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0722 13:25:30.665911 38892 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0722 13:25:30.849953 38892 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "W0722 13:25:31.847973 38892 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "im_height = 64\n",
    "im_width = 64\n",
    "\n",
    "input_img = Input((im_height, im_width, 1), name='img')\n",
    "\n",
    "model_simple = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "model_simple.compile(optimizer=Adam(), loss=dice_loss, metrics=['accuracy', dice_coef])\n",
    "model_simple.load_weights('../res/plaq-u-net_simple.h5')\n",
    "\n",
    "model_aug = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "model_aug.compile(optimizer=Adam(), loss=dice_loss, metrics=['accuracy', dice_coef])\n",
    "model_aug.load_weights('../res/plaq-u-net_aug.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patching and consensus map calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect4multipatches(img, model):\n",
    "    \n",
    "    steps = int((img.shape[0]-64)/4)+1\n",
    "    \n",
    "    M = np.empty((img.shape[0], img.shape[1], steps*steps))\n",
    "    M[:] = np.NaN\n",
    "    img_patch = np.zeros((steps*steps, 64, 64, 1))\n",
    "    c = 0\n",
    "\n",
    "    for i in range (0, steps):\n",
    "        for j in range (0, steps):\n",
    "            \n",
    "            img_crop = img[4*i:4*i+64, 4*j:4*j+64]\n",
    "            img_patch[c, ..., 0] = img_crop.copy()\n",
    "            c += 1\n",
    "            \n",
    "    img_patch_pred = model.predict(img_patch, verbose=0)\n",
    "    \n",
    "    c = 0\n",
    "    for i in range (0, steps):\n",
    "        for j in range (0, steps):\n",
    "            M[4*i:4*i+64, 4*j:4*j+64, c] = img_patch_pred[c, ..., 0]\n",
    "            c += 1\n",
    "            \n",
    "    M_concord = np.nanmean(M, axis = 2)\n",
    "    \n",
    "    del M\n",
    "            \n",
    "    return M_concord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CA probability maps calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data loading and pre-processing functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading DICOM to array from the file path\n",
    "def path2array(dcm_path):\n",
    "    arr_dcm = pydicom.read_file(dcm_path, force = True)\n",
    "    arr_dcm.file_meta.TransferSyntaxUID = pydicom.uid.ImplicitVRLittleEndian\n",
    "    arr = arr_dcm.pixel_array\n",
    "    return arr\n",
    "\n",
    "# N4 bias field correction\n",
    "def correctBiasField(img_input):\n",
    "    \n",
    "    corrected = False\n",
    "    img_output = np.zeros(img_input.shape)\n",
    "\n",
    "    while not corrected:\n",
    "\n",
    "        try:\n",
    "            corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "            inputImage = sitk.GetImageFromArray(img_input)\n",
    "            inputImage = sitk.Cast(inputImage, sitk.sitkFloat32)\n",
    "            output = corrector.Execute(inputImage)\n",
    "            img_output = sitk.GetArrayFromImage(output)\n",
    "            corrected = True\n",
    "        except:\n",
    "            print ('BFC failed')\n",
    "\n",
    "    return img_output\n",
    "\n",
    "# zooming images to defined voxel size and array shape (with cropping/padding)\n",
    "# from: https://stackoverflow.com/questions/37119071/scipy-rotate-and-zoom-an-image-without-changing-its-dimensions\n",
    "def clipped_zoom(img, zoom_factor, **kwargs):\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # For multichannel images we don't want to apply the zoom factor to the RGB\n",
    "    # dimension, so instead we create a tuple of zoom factors, one per array\n",
    "    # dimension, with 1's for any trailing dimensions after the width and height.\n",
    "    zoom_tuple = (zoom_factor,) * 2 + (1,) * (img.ndim - 2)\n",
    "\n",
    "    # Zooming out\n",
    "    if zoom_factor < 1:\n",
    "\n",
    "        # Bounding box of the zoomed-out image within the output array\n",
    "        zh = int(np.round(h * zoom_factor))\n",
    "        zw = int(np.round(w * zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        # Zero-padding\n",
    "        out = np.zeros_like(img)\n",
    "        out[top:top+zh, left:left+zw] = zoom(img, zoom_tuple, **kwargs)\n",
    "\n",
    "    # Zooming in\n",
    "    elif zoom_factor > 1:\n",
    "\n",
    "        # Bounding box of the zoomed-in region within the input array\n",
    "        zh = int(np.round(h / zoom_factor))\n",
    "        zw = int(np.round(w / zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        out = zoom(img[top:top+zh, left:left+zw], zoom_tuple, **kwargs)\n",
    "\n",
    "        # `out` might still be slightly larger than `img` due to rounding, so\n",
    "        # trim off any extra pixels at the edges\n",
    "        trim_top = ((out.shape[0] - h) // 2)\n",
    "        trim_left = ((out.shape[1] - w) // 2)\n",
    "        out = out[trim_top:trim_top+h, trim_left:trim_left+w]\n",
    "\n",
    "    # If zoom_factor == 1, just return the input array\n",
    "    else:\n",
    "        out = img\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting patient names from the test set (from training script):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_names_test = ['AMC012', 'AMC006', 'MUMC094', 'MUMC027', 'MUMC079', 'MUMC052', 'MUMC127', 'MUMC071', 'MUMC038',\n",
    "                  'MUMC093', 'MUMC107', 'MUMC022', 'MUMC114', 'MUMC115', 'MUMC069', 'MUMC130', 'MUMC036', 'MUMC007', \n",
    "                  'MUMC059', 'MUMC080', 'UMCU036', 'UMCU025', 'UMCU008', 'UMCU034']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dir = '../data/'\n",
    "results_dir_simple = '../res/maps/T1w/plaq-u-net_simple/'\n",
    "results_dir_aug = '../res/maps/T1w/plaq-u-net_aug/'\n",
    "\n",
    "for sub_name in sub_names_test:\n",
    "    \n",
    "    sub_img_names = glob.glob(ds_dir+sub_name+'*/T1W_*.dcm')\n",
    "    \n",
    "    for sub_img_name in sub_img_names:\n",
    "        \n",
    "        img = path2array(sub_img_name)\n",
    "        img_test = img[8:-8,8:-8].copy()\n",
    "        img_min = np.min(img_test)\n",
    "        img_max = np.max(img_test)\n",
    "        img_norm = np.copy((img_test - img_min)/(img_max - img_min)*255).astype(np.uint8)\n",
    "\n",
    "        vessels_pred_multi_simple = detect4multipatches(img_norm, model_simple)\n",
    "        vessels_pred_multi_aug = detect4multipatches(img_norm, model_aug)\n",
    "        \n",
    "        np.save(results_dir_simple + sub_name + '/' + sub_img_name.split(os.sep)[2][-10:-4] + '.npy', \n",
    "                vessels_pred_multi_simple)\n",
    "        np.save(results_dir_aug + sub_name + '/' + sub_img_name.split(os.sep)[2][-10:-4] + '.npy', \n",
    "                vessels_pred_multi_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "ds_dir = '../data/'\n",
    "results_dir_simple = '../res/maps/T1wCE/plaq-u-net_simple/'\n",
    "results_dir_aug = '../res/maps/T1wCE/plaq-u-net_aug/'\n",
    "\n",
    "for sub_name in sub_names_test:\n",
    "    \n",
    "    sub_img_names = glob.glob(ds_dir+sub_name+'*/T1W-contrast_*.dcm')\n",
    "    \n",
    "    for sub_img_name in sub_img_names:\n",
    "        \n",
    "        img = path2array(sub_img_name)\n",
    "        img_test = img[8:-8,8:-8].copy()\n",
    "        img_min = np.min(img_test)\n",
    "        img_max = np.max(img_test)\n",
    "        img_norm = np.copy((img_test - img_min)/(img_max - img_min)*255).astype(np.uint8)\n",
    "\n",
    "        vessels_pred_multi_simple = detect4multipatches(img_norm, model_simple)\n",
    "        vessels_pred_multi_aug = detect4multipatches(img_norm, model_aug)\n",
    "        \n",
    "        np.save(results_dir_simple + sub_name + '/' + sub_img_name.split(os.sep)[2][-10:-4] + '.npy', \n",
    "                vessels_pred_multi_simple)\n",
    "        np.save(results_dir_aug + sub_name + '/' + sub_img_name.split(os.sep)[2][-10:-4] + '.npy', \n",
    "                vessels_pred_multi_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "ds_dir = '../data/'\n",
    "results_dir_simple = '../res/maps/T2w/plaq-u-net_simple/'\n",
    "results_dir_aug = '../res/maps/T2w/plaq-u-net_aug/'\n",
    "\n",
    "for sub_name in sub_names_test:\n",
    "    \n",
    "    sub_img_names = glob.glob(ds_dir+sub_name+'*/T2W_*.dcm')\n",
    "    \n",
    "    for sub_img_name in sub_img_names:\n",
    "        \n",
    "        img = path2array(sub_img_name)\n",
    "        img_test = img[8:-8,8:-8].copy()\n",
    "        img_min = np.min(img_test)\n",
    "        img_max = np.max(img_test)\n",
    "        img_norm = np.copy((img_test - img_min)/(img_max - img_min)*255).astype(np.uint8)\n",
    "\n",
    "        vessels_pred_multi_simple = detect4multipatches(img_norm, model_simple)\n",
    "        vessels_pred_multi_aug = detect4multipatches(img_norm, model_aug)\n",
    "        \n",
    "        np.save(results_dir_simple + sub_name + '/' + sub_img_name.split(os.sep)[2][-10:-4] + '.npy', \n",
    "                vessels_pred_multi_simple)\n",
    "        np.save(results_dir_aug + sub_name + '/' + sub_img_name.split(os.sep)[2][-10:-4] + '.npy', \n",
    "                vessels_pred_multi_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 EMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patient names from EMC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_names_emc = ['EMC003', 'EMC004', 'EMC005', 'EMC007', 'EMC008', 'EMC009', 'EMC011', \n",
    "                 'EMC015', 'EMC018', 'EMC020', 'EMC024', 'EMC027', 'EMC029', 'EMC031', \n",
    "                 'EMC032', 'EMC034', 'EMC035', 'EMC036', 'EMC038', 'EMC041', 'EMC042', \n",
    "                 'EMC043', 'EMC045', 'EMC046', 'EMC047', 'EMC048', 'EMC049', 'EMC050', \n",
    "                 'EMC051', 'EMC052', 'EMC054', 'EMC055', 'EMC056', 'EMC057']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating CA probability maps and saving to the results folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n"
     ]
    }
   ],
   "source": [
    "ds_dir = '../data/'\n",
    "results_dir_simple = '../res/maps/plaq-u-net_simple/'\n",
    "results_dir_aug = '../res/maps/plaq-u-net_aug/'\n",
    "\n",
    "for sub_name in sub_names_emc:\n",
    "    \n",
    "    sub_img_names = glob.glob(ds_dir+sub_name+'*/T1W_*.dcm')\n",
    "    \n",
    "    for sub_img_name in sub_img_names:\n",
    "        \n",
    "        img = path2array(sub_img_name)\n",
    "        #img_test = correctBiasField(img)\n",
    "        img_test = img.copy()\n",
    "        img_min = np.min(img_test)\n",
    "        img_max = np.max(img_test)\n",
    "        img_norm = np.copy((img_test - img_min)/(img_max - img_min)*255).astype(np.uint8)\n",
    "        \n",
    "        img_res = cv2.resize(img_norm.copy(), dsize=(512, 512), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        vessels_pred_multi_simple = detect4multipatches(img_res, model_simple)\n",
    "        vessels_pred_multi_aug = detect4multipatches(img_res, model_aug)\n",
    "        \n",
    "        vessels_pred_multi_simple_res = cv2.resize(vessels_pred_multi_simple.copy(), \n",
    "                                                   dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "        vessels_pred_multi_aug_res = cv2.resize(vessels_pred_multi_aug.copy(), \n",
    "                                                dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        np.save(results_dir_simple + sub_name + '/' + sub_img_name.split(os.sep)[2][-17:-11] + '.npy', \n",
    "                vessels_pred_multi_simple_res)\n",
    "        np.save(results_dir_aug + sub_name + '/' + sub_img_name.split(os.sep)[2][-17:-11] + '.npy', \n",
    "                vessels_pred_multi_aug_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
