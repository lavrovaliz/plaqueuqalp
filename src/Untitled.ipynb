{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seg_metrics.seg_metrics as sg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "import pydicom\n",
    "from skimage import morphology\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import label, regionprops\n",
    "import cv2\n",
    "from skimage.morphology import skeletonize, skeletonize_3d\n",
    "import pickle\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from scipy.stats import gaussian_kde\n",
    "from matplotlib.patches import Rectangle\n",
    "from skimage import morphology\n",
    "import glob\n",
    "from sklearn.metrics import r2_score\n",
    "import scipy\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import wilcoxon\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lookup_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icc(Y, icc_type='ICC(2,1)'):\n",
    "    ''' Calculate intraclass correlation coefficient\n",
    "\n",
    "    ICC Formulas are based on:\n",
    "    Shrout, P. E., & Fleiss, J. L. (1979). Intraclass correlations: uses in\n",
    "    assessing rater reliability. Psychological bulletin, 86(2), 420.\n",
    "    icc1:  x_ij = mu + beta_j + w_ij\n",
    "    icc2/3:  x_ij = mu + alpha_i + beta_j + (ab)_ij + epsilon_ij\n",
    "    Code modifed from nipype algorithms.icc\n",
    "    https://github.com/nipy/nipype/blob/master/nipype/algorithms/icc.py\n",
    "\n",
    "    Args:\n",
    "        Y: The data Y are entered as a 'table' ie. subjects are in rows and repeated\n",
    "            measures in columns\n",
    "        icc_type: type of ICC to calculate. (ICC(2,1), ICC(2,k), ICC(3,1), ICC(3,k)) \n",
    "    Returns:\n",
    "        ICC: (np.array) intraclass correlation coefficient\n",
    "    '''\n",
    "\n",
    "    [n, k] = Y.shape\n",
    "\n",
    "    # Degrees of Freedom\n",
    "    dfc = k - 1\n",
    "    dfe = (n - 1) * (k-1)\n",
    "    dfr = n - 1\n",
    "\n",
    "    # Sum Square Total\n",
    "    mean_Y = np.mean(Y)\n",
    "    SST = ((Y - mean_Y) ** 2).sum()\n",
    "\n",
    "    # create the design matrix for the different levels\n",
    "    x = np.kron(np.eye(k), np.ones((n, 1)))  # sessions\n",
    "    x0 = np.tile(np.eye(n), (k, 1))  # subjects\n",
    "    X = np.hstack([x, x0])\n",
    "\n",
    "    # Sum Square Error\n",
    "    predicted_Y = np.dot(np.dot(np.dot(X, np.linalg.pinv(np.dot(X.T, X))),\n",
    "                                X.T), Y.flatten('F'))\n",
    "    residuals = Y.flatten('F') - predicted_Y\n",
    "    SSE = (residuals ** 2).sum()\n",
    "\n",
    "    MSE = SSE / dfe\n",
    "\n",
    "    # Sum square column effect - between colums\n",
    "    SSC = ((np.mean(Y, 0) - mean_Y) ** 2).sum() * n\n",
    "    MSC = SSC / dfc  # / n (without n in SPSS results)\n",
    "\n",
    "    # Sum Square subject effect - between rows/subjects\n",
    "    SSR = SST - SSC - SSE\n",
    "    MSR = SSR / dfr\n",
    "\n",
    "    if icc_type == 'icc1':\n",
    "        # ICC(2,1) = (mean square subject - mean square error) /\n",
    "        # (mean square subject + (k-1)*mean square error +\n",
    "        # k*(mean square columns - mean square error)/n)\n",
    "        # ICC = (MSR - MSRW) / (MSR + (k-1) * MSRW)\n",
    "        NotImplementedError(\"This method isn't implemented yet.\")\n",
    "\n",
    "    elif icc_type == 'ICC(2,1)' or icc_type == 'ICC(2,k)':\n",
    "        # ICC(2,1) = (mean square subject - mean square error) /\n",
    "        # (mean square subject + (k-1)*mean square error +\n",
    "        # k*(mean square columns - mean square error)/n)\n",
    "        if icc_type == 'ICC(2,k)':\n",
    "            k = 1\n",
    "        ICC = (MSR - MSE) / (MSR + (k-1) * MSE + k * (MSC - MSE) / n)\n",
    "\n",
    "    elif icc_type == 'ICC(3,1)' or icc_type == 'ICC(3,k)':\n",
    "        # ICC(3,1) = (mean square subject - mean square error) /\n",
    "        # (mean square subject + (k-1)*mean square error)\n",
    "        if icc_type == 'ICC(3,k)':\n",
    "            k = 1\n",
    "        ICC = (MSR - MSE) / (MSR + (k-1) * MSE)\n",
    "\n",
    "    return ICC\n",
    "\n",
    "def cl_score(v, s):\n",
    "    \"\"\"[this function computes the skeleton volume overlap]\n",
    "    Args:\n",
    "        v ([bool]): [image]\n",
    "        s ([bool]): [skeleton]\n",
    "    Returns:\n",
    "        [float]: [computed skeleton volume intersection]\n",
    "    \"\"\"\n",
    "    return np.sum(v*s)/np.sum(s)\n",
    "\n",
    "\n",
    "def clDice(v_l, v_p):\n",
    "    \"\"\"[this function computes the cldice metric]\n",
    "    Args:\n",
    "        v_p ([bool]): [predicted image]\n",
    "        v_l ([bool]): [ground truth image]\n",
    "    Returns:\n",
    "        [float]: [cldice metric]\n",
    "    \"\"\"\n",
    "    if len(v_p.shape)==2:\n",
    "        tprec = cl_score(v_p,skeletonize(v_l))\n",
    "        tsens = cl_score(v_l,skeletonize(v_p))\n",
    "    elif len(v_p.shape)==3:\n",
    "        tprec = cl_score(v_p,skeletonize_3d(v_l))\n",
    "        tsens = cl_score(v_l,skeletonize_3d(v_p))\n",
    "    return 2*tprec*tsens/(tprec+tsens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dice_coef(y_true, y_pred):\n",
    "\n",
    "    smooth=1\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jaccard_coef(y_true, y_pred):\n",
    "\n",
    "    smooth=1\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    union = np.sum(y_true_f) + np.sum(y_pred_f) - intersection\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEdgeOfMask(mask):\n",
    "    \n",
    "    edge = np.zeros_like(mask)\n",
    "    mask_pixels = np.where(mask > 0)\n",
    "\n",
    "    for idx in range(0,mask_pixels[0].size):\n",
    "\n",
    "        x = mask_pixels[0][idx]\n",
    "        y = mask_pixels[1][idx]\n",
    "        z = mask_pixels[2][idx]\n",
    "\n",
    "        if mask[x-1:x+2, y-1:y+2, z-1:z+2].sum() < 27:\n",
    "            edge[x,y,z] = 1\n",
    "            \n",
    "    return edge\n",
    "\n",
    "def compute_AddedPathLength(mask_true, mask_pred, spacing_mm):\n",
    "    \n",
    "    edge_true = getEdgeOfMask(mask_true)\n",
    "    edge_pred = getEdgeOfMask(mask_pred)\n",
    "   \n",
    "    apl = (edge_true > edge_pred).astype(int).sum()\n",
    "    \n",
    "    return apl*spacing_mm[0]*spacing_mm[1]*spacing_mm[2]/10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nsd(img_1, img_2, tau):\n",
    "    \n",
    "    img_1_b = getEdgeOfMask(img_1)\n",
    "    img_2_b = getEdgeOfMask(img_2)\n",
    "    \n",
    "    strel_size = 1 + tau*2\n",
    "    strel = np.ones((strel_size, strel_size, strel_size))\n",
    "    \n",
    "    img_1_bb = morphology.binary_dilation(img_1_b, strel)\n",
    "    img_2_bb = morphology.binary_dilation(img_2_b, strel)\n",
    "    \n",
    "    int_1 = img_1_b*img_2_bb\n",
    "    int_2 = img_1_bb*img_2_b\n",
    "    \n",
    "    return (np.sum(int_1)+np.sum(int_2))/(np.sum(img_1_b) + np.sum(img_2_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hausdorf_surf_distance(mask_gt, mask_pred, spacing_mm, percent=95):\n",
    "    \"\"\"Computes the robust Hausdorff distance. \"Robust\", because it uses the `percent` percentile \n",
    "    of the distances instead of the maximum distance. The percentage is computed by correctly taking \n",
    "    the area of each surface element into account.\n",
    "    Args:\n",
    "    mask_gt: 3-dim Numpy array of type bool. The ground truth mask.\n",
    "    mask_pred: 3-dim Numpy array of type bool. The predicted mask.\n",
    "    spacing_mm: 3-element list-like structure. Voxel spacing in x0, x1 and x2 direction.\n",
    "    percent: a float value between 0 and 100.\n",
    "    Returns:\n",
    "    a float value. The robust Hausdorff distance in mm. If one of the masks\n",
    "    is empty, the corresponding lists are empty and all distances in the other\n",
    "    list are `inf`.\n",
    "    \"\"\"\n",
    "\n",
    "    neighbour_code_to_surface_area = np.zeros([256])\n",
    "    for code in range(256):\n",
    "        normals = np.array(lookup_tables._NEIGHBOUR_CODE_TO_NORMALS[code])\n",
    "        sum_area = 0\n",
    "        for normal_idx in range(normals.shape[0]):\n",
    "            # normal vector\n",
    "            n = np.zeros([3])\n",
    "            n[0] = normals[normal_idx, 0] * spacing_mm[1] * spacing_mm[2]\n",
    "            n[1] = normals[normal_idx, 1] * spacing_mm[0] * spacing_mm[2]\n",
    "            n[2] = normals[normal_idx, 2] * spacing_mm[0] * spacing_mm[1]\n",
    "            area = np.linalg.norm(n)\n",
    "            sum_area += area\n",
    "        neighbour_code_to_surface_area[code] = sum_area\n",
    "\n",
    "    # compute the bounding box of the masks to trim\n",
    "    # the volume to the smallest possible processing subvolume\n",
    "    mask_all = mask_gt | mask_pred\n",
    "    bbox_min = np.zeros(3, np.int64)\n",
    "    bbox_max = np.zeros(3, np.int64)\n",
    "\n",
    "    # max projection to the x0-axis\n",
    "    proj_0 = np.max(np.max(mask_all, axis=2), axis=1)\n",
    "    idx_nonzero_0 = np.nonzero(proj_0)[0]\n",
    "    if len(idx_nonzero_0) == 0:  # pylint: disable=g-explicit-length-test\n",
    "        return {\"distances_gt_to_pred\": np.array([]),\n",
    "                \"distances_pred_to_gt\": np.array([]),\n",
    "                \"surfel_areas_gt\": np.array([]),\n",
    "                \"surfel_areas_pred\": np.array([])}\n",
    "\n",
    "    bbox_min[0] = np.min(idx_nonzero_0)\n",
    "    bbox_max[0] = np.max(idx_nonzero_0)\n",
    "\n",
    "    # max projection to the x1-axis\n",
    "    proj_1 = np.max(np.max(mask_all, axis=2), axis=0)\n",
    "    idx_nonzero_1 = np.nonzero(proj_1)[0]\n",
    "    bbox_min[1] = np.min(idx_nonzero_1)\n",
    "    bbox_max[1] = np.max(idx_nonzero_1)\n",
    "\n",
    "    # max projection to the x2-axis\n",
    "    proj_2 = np.max(np.max(mask_all, axis=1), axis=0)\n",
    "    idx_nonzero_2 = np.nonzero(proj_2)[0]\n",
    "    bbox_min[2] = np.min(idx_nonzero_2)\n",
    "    bbox_max[2] = np.max(idx_nonzero_2)\n",
    "\n",
    "    # crop the processing subvolume.\n",
    "    # we need to zeropad the cropped region with 1 voxel at the lower,\n",
    "    # the right and the back side. This is required to obtain the \"full\"\n",
    "    # convolution result with the 2x2x2 kernel\n",
    "    cropmask_gt = np.zeros((bbox_max - bbox_min)+2, np.uint8)\n",
    "    cropmask_pred = np.zeros((bbox_max - bbox_min)+2, np.uint8)\n",
    "\n",
    "    cropmask_gt[0:-1, 0:-1, 0:-1] = mask_gt[bbox_min[0]:bbox_max[0]+1,bbox_min[1]:bbox_max[1]+1,\n",
    "                                          bbox_min[2]:bbox_max[2]+1]\n",
    "\n",
    "    cropmask_pred[0:-1, 0:-1, 0:-1] = mask_pred[bbox_min[0]:bbox_max[0]+1,bbox_min[1]:bbox_max[1]+1,\n",
    "                                              bbox_min[2]:bbox_max[2]+1]\n",
    "\n",
    "    # compute the neighbour code (local binary pattern) for each voxel\n",
    "    # the resultsing arrays are spacially shifted by minus half a voxel in each\n",
    "    # axis.\n",
    "    # i.e. the points are located at the corners of the original voxels\n",
    "    kernel = np.array([[[128, 64],[32, 16]],[[8, 4],[2, 1]]])\n",
    "    \n",
    "    neighbour_code_map_gt = ndimage.filters.correlate(cropmask_gt.astype(np.uint8), kernel, mode=\"constant\", cval=0)\n",
    "    neighbour_code_map_pred = ndimage.filters.correlate(cropmask_pred.astype(np.uint8), kernel, mode=\"constant\", cval=0)\n",
    "\n",
    "    # create masks with the surface voxels\n",
    "    borders_gt = ((neighbour_code_map_gt != 0) & (neighbour_code_map_gt != 255))\n",
    "    borders_pred = ((neighbour_code_map_pred != 0) &(neighbour_code_map_pred != 255))\n",
    "\n",
    "    # compute the distance transform (closest distance of each voxel to the surface voxels)\n",
    "    if borders_gt.any():\n",
    "        distmap_gt = ndimage.morphology.distance_transform_edt(~borders_gt, sampling=spacing_mm)\n",
    "    else:\n",
    "        distmap_gt = np.Inf * np.ones(borders_gt.shape)\n",
    "\n",
    "    if borders_pred.any():\n",
    "        distmap_pred = ndimage.morphology.distance_transform_edt(~borders_pred, sampling=spacing_mm)\n",
    "    else:\n",
    "        distmap_pred = np.Inf * np.ones(borders_pred.shape)\n",
    "\n",
    "    # compute the area of each surface element\n",
    "    surface_area_map_gt = neighbour_code_to_surface_area[neighbour_code_map_gt]\n",
    "    surface_area_map_pred = neighbour_code_to_surface_area[neighbour_code_map_pred]\n",
    "\n",
    "    # create a list of all surface elements with distance and area\n",
    "    distances_gt_to_pred = distmap_pred[borders_gt]\n",
    "    distances_pred_to_gt = distmap_gt[borders_pred]\n",
    "    surfel_areas_gt = surface_area_map_gt[borders_gt]\n",
    "    surfel_areas_pred = surface_area_map_pred[borders_pred]\n",
    "\n",
    "    # sort them by distance\n",
    "    if distances_gt_to_pred.shape != (0,):\n",
    "        sorted_surfels_gt = np.array(sorted(zip(distances_gt_to_pred, surfel_areas_gt)))\n",
    "        distances_gt_to_pred = sorted_surfels_gt[:, 0]\n",
    "        surfel_areas_gt = sorted_surfels_gt[:, 1]\n",
    "\n",
    "    if distances_pred_to_gt.shape != (0,):\n",
    "        sorted_surfels_pred = np.array(sorted(zip(distances_pred_to_gt, surfel_areas_pred)))\n",
    "        distances_pred_to_gt = sorted_surfels_pred[:, 0]\n",
    "        surfel_areas_pred = sorted_surfels_pred[:, 1]\n",
    "\n",
    "    if len(distances_gt_to_pred) > 0:  # pylint: disable=g-explicit-length-test\n",
    "        surfel_areas_cum_gt = np.cumsum(surfel_areas_gt) / np.sum(surfel_areas_gt)\n",
    "        idx = np.searchsorted(surfel_areas_cum_gt, percent/100.0)\n",
    "        perc_distance_gt_to_pred = distances_gt_to_pred[min(idx, len(distances_gt_to_pred)-1)]\n",
    "        max_distance_gt_to_pred = np.max(distances_gt_to_pred)\n",
    "    else:\n",
    "        perc_distance_gt_to_pred = np.Inf\n",
    "        max_distance_gt_to_pred = np.Inf\n",
    "\n",
    "    if len(distances_pred_to_gt) > 0:  # pylint: disable=g-explicit-length-test\n",
    "        surfel_areas_cum_pred = (np.cumsum(surfel_areas_pred) /np.sum(surfel_areas_pred))\n",
    "        idx = np.searchsorted(surfel_areas_cum_pred, percent/100.0)\n",
    "        perc_distance_pred_to_gt = distances_pred_to_gt[min(idx, len(distances_pred_to_gt)-1)]\n",
    "        max_distance_pred_to_gt = np.max(distances_pred_to_gt)\n",
    "    else:\n",
    "        perc_distance_pred_to_gt = np.Inf\n",
    "        max_distance_pred_to_gt = np.Inf\n",
    "\n",
    "    return max(max_distance_gt_to_pred, max_distance_pred_to_gt), max(perc_distance_gt_to_pred, perc_distance_pred_to_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_names_test = ['AMC012', 'AMC006', \n",
    "                  'MUMC094', 'MUMC027', 'MUMC079', 'MUMC052', 'MUMC127', 'MUMC071', 'MUMC038', 'MUMC093', 'MUMC107', \n",
    "                  'MUMC022', 'MUMC114', 'MUMC115', 'MUMC069', 'MUMC130', 'MUMC036', 'MUMC007', 'MUMC059', 'MUMC080', \n",
    "                  'UMCU036', 'UMCU025', 'UMCU008', 'UMCU034']\n",
    "\n",
    "sub_names_emc = ['EMC003', 'EMC004', 'EMC005', 'EMC007', 'EMC008', 'EMC009', 'EMC011', \n",
    "                 'EMC015', 'EMC018', 'EMC020', 'EMC024', 'EMC027', 'EMC029', 'EMC031', \n",
    "                 'EMC032', 'EMC034', 'EMC035', 'EMC036', 'EMC038', 'EMC041', 'EMC042', \n",
    "                 'EMC043', 'EMC045', 'EMC046', 'EMC047', 'EMC048', 'EMC049', 'EMC050', \n",
    "                 'EMC051', 'EMC052', 'EMC054', 'EMC055', 'EMC056', 'EMC057']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "nifti_dirname_GT_test = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\test\\test_GT\"\n",
    "nifti_dirname_GT_t2w = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t2w\\t2w_GT\"\n",
    "nifti_dirname_GT_t1wce = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t1wce\\t1wce_GT\"\n",
    "nifti_dirname_GT_emc = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\emc\\emc_GT\"\n",
    "\n",
    "nifti_dirname_nnunet_test = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\test\\test_nnunet\"\n",
    "nifti_dirname_nnunet_t2w = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t2w\\t2w_nnunet\"\n",
    "nifti_dirname_nnunet_t1wce = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t1wce\\t1wce_nnunet\"\n",
    "nifti_dirname_nnunet_emc = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\emc\\emc_nnunet\"\n",
    "\n",
    "nifti_dirname_nnunet_test_sm = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\test\\test_nnunet_p\"\n",
    "nifti_dirname_nnunet_t2w_sm = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t2w\\t2w_nnunet_p\"\n",
    "nifti_dirname_nnunet_t1wce_sm = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t1wce\\t1wce_nnunet_p\"\n",
    "nifti_dirname_nnunet_emc_sm = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\emc\\emc_nnunet_p\"\n",
    "\n",
    "nifti_dirname_plaqunet_test = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\test\\test_plaqunet\"\n",
    "nifti_dirname_plaqunet_t2w = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t2w\\t2w_plaqunet\"\n",
    "nifti_dirname_plaqunet_t1wce = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t1wce\\t1wce_plaqunet\"\n",
    "nifti_dirname_plaqunet_emc = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\emc\\emc_plaqunet\"\n",
    "\n",
    "nifti_dirname_plaqunet_test_sm = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\test\\test_plaqunet_p\"\n",
    "nifti_dirname_plaqunet_t2w_sm = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t2w\\t2w_plaqunet_p\"\n",
    "nifti_dirname_plaqunet_t1wce_sm=r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t1wce\\t1wce_plaqunet_p\"\n",
    "nifti_dirname_plaqunet_emc_sm = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\emc\\emc_plaqunet_p\"\n",
    "\n",
    "nifti_dirname_plaqumap_test = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\test\\test_plaqumap\"\n",
    "nifti_dirname_plaqumap_t2w = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t2w\\t2w_plaqumap\"\n",
    "nifti_dirname_plaqumap_t1wce = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t1wce\\t1wce_plaqumap\"\n",
    "nifti_dirname_plaqumap_emc = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\emc\\emc_plaqumap\"\n",
    "\n",
    "nifti_dirname_plaqumap_test_sm = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\test\\test_plaqumap_p\"\n",
    "nifti_dirname_plaqumap_t2w_sm = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t2w\\t2w_plaqumap_p\"\n",
    "nifti_dirname_plaqumap_t1wce_sm=r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t1wce\\t1wce_plaqumap_p\"\n",
    "nifti_dirname_plaqumap_emc_sm = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\emc\\emc_plaqumap_p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_df(sub_names, dirname_gt, dirname_pred):\n",
    "\n",
    "    df_scores = []\n",
    "\n",
    "    for sub_name in sub_names:\n",
    "        \n",
    "        print (sub_name)\n",
    "\n",
    "        filename_gt = os.path.join(dirname_gt, sub_name + '.nii.gz')\n",
    "        filename_pred = os.path.join(dirname_pred, sub_name + '.nii.gz')\n",
    "\n",
    "        mask_gt = sitk.ReadImage(filename_gt)\n",
    "        mask_pred = sitk.ReadImage(filename_pred)\n",
    "\n",
    "        mask_gt = sitk.GetArrayFromImage(mask_gt)\n",
    "        mask_pred = sitk.GetArrayFromImage(mask_pred)\n",
    "\n",
    "        rec = {'sub': sub_name} \n",
    "        rec['DSC'] = compute_dice_coef(mask_gt, mask_pred)\n",
    "        rec['JSc'] = compute_jaccard_coef(mask_gt, mask_pred)\n",
    "\n",
    "        hd_max, hd_95 = compute_hausdorf_surf_distance(mask_gt, mask_pred, [2, 0.303030, 0.303030], percent=95)\n",
    "\n",
    "        rec['hd'] = hd_max\n",
    "        rec['hd95'] = hd_95\n",
    "\n",
    "        rec['clDice'] = clDice(mask_gt, mask_pred)\n",
    "        rec['nsd'] = compute_nsd(mask_gt, mask_pred, tau=1)\n",
    "        rec['apl'] = compute_AddedPathLength(mask_gt, mask_pred, [2, 0.303030, 0.303030])\n",
    "\n",
    "        rec['vol_gt'] = np.sum(mask_gt)\n",
    "        rec['vol_pred'] = np.sum(mask_pred)\n",
    "\n",
    "        rec['vol_diff'] = rec['vol_gt']-rec['vol_pred']\n",
    "        rec['abs_vol_diff'] = abs(rec['vol_gt']-rec['vol_pred'])\n",
    "\n",
    "        df_scores.append(rec)\n",
    "\n",
    "    df_scores = pd.DataFrame(df_scores_test_1)\n",
    "\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMC012\n",
      "AMC006\n",
      "MUMC094\n",
      "MUMC027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: overflow encountered in ulong_scalars\n",
      "C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: overflow encountered in ulong_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUMC079\n",
      "MUMC052\n",
      "MUMC127\n",
      "MUMC071\n",
      "MUMC038\n",
      "MUMC093\n",
      "MUMC107\n",
      "MUMC022\n",
      "MUMC114\n",
      "MUMC115\n",
      "MUMC069\n",
      "MUMC130\n",
      "MUMC036\n",
      "MUMC007\n",
      "MUMC059\n",
      "MUMC080\n",
      "UMCU036\n",
      "UMCU025\n",
      "UMCU008\n",
      "UMCU034\n"
     ]
    }
   ],
   "source": [
    "df_scores_nnunet_test = get_scores_df(sub_names_test, nifti_dirname_GT_test, nifti_dirname_nnunet_test)\n",
    "df_scores_nnunet_t1wce = get_scores_df(sub_names_test, nifti_dirname_GT_t1wce, nifti_dirname_nnunet_t1wce)\n",
    "df_scores_nnunet_t2w = get_scores_df(sub_names_test, nifti_dirname_GT_t2w, nifti_dirname_nnunet_t2w)\n",
    "df_scores_nnunet_emc = get_scores_df(sub_names_emc, nifti_dirname_GT_emc, nifti_dirname_nnunet_emc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
