{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seg_metrics.seg_metrics as sg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "import pydicom\n",
    "from skimage import morphology\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import label, regionprops\n",
    "import cv2\n",
    "from skimage.morphology import skeletonize, skeletonize_3d\n",
    "import pickle\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from scipy.stats import gaussian_kde\n",
    "from matplotlib.patches import Rectangle\n",
    "from skimage import morphology\n",
    "import glob\n",
    "from sklearn.metrics import r2_score\n",
    "import scipy\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import wilcoxon\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lookup_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icc(Y, icc_type='ICC(2,1)'):\n",
    "    ''' Calculate intraclass correlation coefficient\n",
    "\n",
    "    ICC Formulas are based on:\n",
    "    Shrout, P. E., & Fleiss, J. L. (1979). Intraclass correlations: uses in\n",
    "    assessing rater reliability. Psychological bulletin, 86(2), 420.\n",
    "    icc1:  x_ij = mu + beta_j + w_ij\n",
    "    icc2/3:  x_ij = mu + alpha_i + beta_j + (ab)_ij + epsilon_ij\n",
    "    Code modifed from nipype algorithms.icc\n",
    "    https://github.com/nipy/nipype/blob/master/nipype/algorithms/icc.py\n",
    "\n",
    "    Args:\n",
    "        Y: The data Y are entered as a 'table' ie. subjects are in rows and repeated\n",
    "            measures in columns\n",
    "        icc_type: type of ICC to calculate. (ICC(2,1), ICC(2,k), ICC(3,1), ICC(3,k)) \n",
    "    Returns:\n",
    "        ICC: (np.array) intraclass correlation coefficient\n",
    "    '''\n",
    "\n",
    "    [n, k] = Y.shape\n",
    "\n",
    "    # Degrees of Freedom\n",
    "    dfc = k - 1\n",
    "    dfe = (n - 1) * (k-1)\n",
    "    dfr = n - 1\n",
    "\n",
    "    # Sum Square Total\n",
    "    mean_Y = np.mean(Y)\n",
    "    SST = ((Y - mean_Y) ** 2).sum()\n",
    "\n",
    "    # create the design matrix for the different levels\n",
    "    x = np.kron(np.eye(k), np.ones((n, 1)))  # sessions\n",
    "    x0 = np.tile(np.eye(n), (k, 1))  # subjects\n",
    "    X = np.hstack([x, x0])\n",
    "\n",
    "    # Sum Square Error\n",
    "    predicted_Y = np.dot(np.dot(np.dot(X, np.linalg.pinv(np.dot(X.T, X))),\n",
    "                                X.T), Y.flatten('F'))\n",
    "    residuals = Y.flatten('F') - predicted_Y\n",
    "    SSE = (residuals ** 2).sum()\n",
    "\n",
    "    MSE = SSE / dfe\n",
    "\n",
    "    # Sum square column effect - between colums\n",
    "    SSC = ((np.mean(Y, 0) - mean_Y) ** 2).sum() * n\n",
    "    MSC = SSC / dfc  # / n (without n in SPSS results)\n",
    "\n",
    "    # Sum Square subject effect - between rows/subjects\n",
    "    SSR = SST - SSC - SSE\n",
    "    MSR = SSR / dfr\n",
    "\n",
    "    if icc_type == 'icc1':\n",
    "        # ICC(2,1) = (mean square subject - mean square error) /\n",
    "        # (mean square subject + (k-1)*mean square error +\n",
    "        # k*(mean square columns - mean square error)/n)\n",
    "        # ICC = (MSR - MSRW) / (MSR + (k-1) * MSRW)\n",
    "        NotImplementedError(\"This method isn't implemented yet.\")\n",
    "\n",
    "    elif icc_type == 'ICC(2,1)' or icc_type == 'ICC(2,k)':\n",
    "        # ICC(2,1) = (mean square subject - mean square error) /\n",
    "        # (mean square subject + (k-1)*mean square error +\n",
    "        # k*(mean square columns - mean square error)/n)\n",
    "        if icc_type == 'ICC(2,k)':\n",
    "            k = 1\n",
    "        ICC = (MSR - MSE) / (MSR + (k-1) * MSE + k * (MSC - MSE) / n)\n",
    "\n",
    "    elif icc_type == 'ICC(3,1)' or icc_type == 'ICC(3,k)':\n",
    "        # ICC(3,1) = (mean square subject - mean square error) /\n",
    "        # (mean square subject + (k-1)*mean square error)\n",
    "        if icc_type == 'ICC(3,k)':\n",
    "            k = 1\n",
    "        ICC = (MSR - MSE) / (MSR + (k-1) * MSE)\n",
    "\n",
    "    return ICC\n",
    "\n",
    "def cl_score(v, s):\n",
    "    \"\"\"[this function computes the skeleton volume overlap]\n",
    "    Args:\n",
    "        v ([bool]): [image]\n",
    "        s ([bool]): [skeleton]\n",
    "    Returns:\n",
    "        [float]: [computed skeleton volume intersection]\n",
    "    \"\"\"\n",
    "    return np.sum(v*s)/np.sum(s)\n",
    "\n",
    "\n",
    "def clDice(v_l, v_p):\n",
    "    \"\"\"[this function computes the cldice metric]\n",
    "    Args:\n",
    "        v_p ([bool]): [predicted image]\n",
    "        v_l ([bool]): [ground truth image]\n",
    "    Returns:\n",
    "        [float]: [cldice metric]\n",
    "    \"\"\"\n",
    "    if len(v_p.shape)==2:\n",
    "        tprec = cl_score(v_p,skeletonize(v_l))\n",
    "        tsens = cl_score(v_l,skeletonize(v_p))\n",
    "    elif len(v_p.shape)==3:\n",
    "        tprec = cl_score(v_p,skeletonize_3d(v_l))\n",
    "        tsens = cl_score(v_l,skeletonize_3d(v_p))\n",
    "    return 2*tprec*tsens/(tprec+tsens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dice_coef(y_true, y_pred):\n",
    "\n",
    "    smooth=1\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jaccard_coef(y_true, y_pred):\n",
    "\n",
    "    smooth=1\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    union = np.sum(y_true_f) + np.sum(y_pred_f) - intersection\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEdgeOfMask(mask):\n",
    "    \n",
    "    edge = np.zeros_like(mask)\n",
    "    mask_pixels = np.where(mask > 0)\n",
    "\n",
    "    for idx in range(0,mask_pixels[0].size):\n",
    "\n",
    "        x = mask_pixels[0][idx]\n",
    "        y = mask_pixels[1][idx]\n",
    "        z = mask_pixels[2][idx]\n",
    "\n",
    "        if mask[x-1:x+2, y-1:y+2, z-1:z+2].sum() < 27:\n",
    "            edge[x,y,z] = 1\n",
    "            \n",
    "    return edge\n",
    "\n",
    "def compute_AddedPathLength(mask_true, mask_pred, spacing_mm):\n",
    "    \n",
    "    edge_true = getEdgeOfMask(mask_true)\n",
    "    edge_pred = getEdgeOfMask(mask_pred)\n",
    "   \n",
    "    apl = (edge_true > edge_pred).astype(int).sum()\n",
    "    \n",
    "    return apl*spacing_mm[0]*spacing_mm[1]*spacing_mm[2]/10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nsd(img_1, img_2, tau):\n",
    "    \n",
    "    img_1_b = getEdgeOfMask(img_1)\n",
    "    img_2_b = getEdgeOfMask(img_2)\n",
    "    \n",
    "    strel_size = 1 + tau*2\n",
    "    strel = np.ones((strel_size, strel_size, strel_size))\n",
    "    \n",
    "    img_1_bb = morphology.binary_dilation(img_1_b, strel)\n",
    "    img_2_bb = morphology.binary_dilation(img_2_b, strel)\n",
    "    \n",
    "    int_1 = img_1_b*img_2_bb\n",
    "    int_2 = img_1_bb*img_2_b\n",
    "    \n",
    "    return (np.sum(int_1)+np.sum(int_2))/(np.sum(img_1_b) + np.sum(img_2_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hausdorf_surf_distance(mask_gt, mask_pred, spacing_mm, percent=95):\n",
    "    \"\"\"Computes the robust Hausdorff distance. \"Robust\", because it uses the `percent` percentile \n",
    "    of the distances instead of the maximum distance. The percentage is computed by correctly taking \n",
    "    the area of each surface element into account.\n",
    "    Args:\n",
    "    mask_gt: 3-dim Numpy array of type bool. The ground truth mask.\n",
    "    mask_pred: 3-dim Numpy array of type bool. The predicted mask.\n",
    "    spacing_mm: 3-element list-like structure. Voxel spacing in x0, x1 and x2 direction.\n",
    "    percent: a float value between 0 and 100.\n",
    "    Returns:\n",
    "    a float value. The robust Hausdorff distance in mm. If one of the masks\n",
    "    is empty, the corresponding lists are empty and all distances in the other\n",
    "    list are `inf`.\n",
    "    \"\"\"\n",
    "    \n",
    "    mask_gt = mask_gt>0\n",
    "    mask_pred = mask_pred>0\n",
    "\n",
    "    neighbour_code_to_surface_area = np.zeros([256])\n",
    "    for code in range(256):\n",
    "        normals = np.array(lookup_tables._NEIGHBOUR_CODE_TO_NORMALS[code])\n",
    "        sum_area = 0\n",
    "        for normal_idx in range(normals.shape[0]):\n",
    "            # normal vector\n",
    "            n = np.zeros([3])\n",
    "            n[0] = normals[normal_idx, 0] * spacing_mm[1] * spacing_mm[2]\n",
    "            n[1] = normals[normal_idx, 1] * spacing_mm[0] * spacing_mm[2]\n",
    "            n[2] = normals[normal_idx, 2] * spacing_mm[0] * spacing_mm[1]\n",
    "            area = np.linalg.norm(n)\n",
    "            sum_area += area\n",
    "        neighbour_code_to_surface_area[code] = sum_area\n",
    "\n",
    "    # compute the bounding box of the masks to trim\n",
    "    # the volume to the smallest possible processing subvolume\n",
    "    mask_all = mask_gt | mask_pred\n",
    "    bbox_min = np.zeros(3, np.int64)\n",
    "    bbox_max = np.zeros(3, np.int64)\n",
    "\n",
    "    # max projection to the x0-axis\n",
    "    proj_0 = np.max(np.max(mask_all, axis=2), axis=1)\n",
    "    idx_nonzero_0 = np.nonzero(proj_0)[0]\n",
    "    if len(idx_nonzero_0) == 0:  # pylint: disable=g-explicit-length-test\n",
    "        return {\"distances_gt_to_pred\": np.array([]),\n",
    "                \"distances_pred_to_gt\": np.array([]),\n",
    "                \"surfel_areas_gt\": np.array([]),\n",
    "                \"surfel_areas_pred\": np.array([])}\n",
    "\n",
    "    bbox_min[0] = np.min(idx_nonzero_0)\n",
    "    bbox_max[0] = np.max(idx_nonzero_0)\n",
    "\n",
    "    # max projection to the x1-axis\n",
    "    proj_1 = np.max(np.max(mask_all, axis=2), axis=0)\n",
    "    idx_nonzero_1 = np.nonzero(proj_1)[0]\n",
    "    bbox_min[1] = np.min(idx_nonzero_1)\n",
    "    bbox_max[1] = np.max(idx_nonzero_1)\n",
    "\n",
    "    # max projection to the x2-axis\n",
    "    proj_2 = np.max(np.max(mask_all, axis=1), axis=0)\n",
    "    idx_nonzero_2 = np.nonzero(proj_2)[0]\n",
    "    bbox_min[2] = np.min(idx_nonzero_2)\n",
    "    bbox_max[2] = np.max(idx_nonzero_2)\n",
    "\n",
    "    # crop the processing subvolume.\n",
    "    # we need to zeropad the cropped region with 1 voxel at the lower,\n",
    "    # the right and the back side. This is required to obtain the \"full\"\n",
    "    # convolution result with the 2x2x2 kernel\n",
    "    cropmask_gt = np.zeros((bbox_max - bbox_min)+2, np.uint8)\n",
    "    cropmask_pred = np.zeros((bbox_max - bbox_min)+2, np.uint8)\n",
    "\n",
    "    cropmask_gt[0:-1, 0:-1, 0:-1] = mask_gt[bbox_min[0]:bbox_max[0]+1,bbox_min[1]:bbox_max[1]+1,\n",
    "                                          bbox_min[2]:bbox_max[2]+1]\n",
    "\n",
    "    cropmask_pred[0:-1, 0:-1, 0:-1] = mask_pred[bbox_min[0]:bbox_max[0]+1,bbox_min[1]:bbox_max[1]+1,\n",
    "                                              bbox_min[2]:bbox_max[2]+1]\n",
    "\n",
    "    # compute the neighbour code (local binary pattern) for each voxel\n",
    "    # the resultsing arrays are spacially shifted by minus half a voxel in each\n",
    "    # axis.\n",
    "    # i.e. the points are located at the corners of the original voxels\n",
    "    kernel = np.array([[[128, 64],[32, 16]],[[8, 4],[2, 1]]])\n",
    "    \n",
    "    neighbour_code_map_gt = ndimage.filters.correlate(cropmask_gt.astype(np.uint8), kernel, mode=\"constant\", cval=0)\n",
    "    neighbour_code_map_pred = ndimage.filters.correlate(cropmask_pred.astype(np.uint8), kernel, mode=\"constant\", cval=0)\n",
    "\n",
    "    # create masks with the surface voxels\n",
    "    borders_gt = ((neighbour_code_map_gt != 0) & (neighbour_code_map_gt != 255))\n",
    "    borders_pred = ((neighbour_code_map_pred != 0) &(neighbour_code_map_pred != 255))\n",
    "\n",
    "    # compute the distance transform (closest distance of each voxel to the surface voxels)\n",
    "    if borders_gt.any():\n",
    "        distmap_gt = ndimage.morphology.distance_transform_edt(~borders_gt, sampling=spacing_mm)\n",
    "    else:\n",
    "        distmap_gt = np.Inf * np.ones(borders_gt.shape)\n",
    "\n",
    "    if borders_pred.any():\n",
    "        distmap_pred = ndimage.morphology.distance_transform_edt(~borders_pred, sampling=spacing_mm)\n",
    "    else:\n",
    "        distmap_pred = np.Inf * np.ones(borders_pred.shape)\n",
    "\n",
    "    # compute the area of each surface element\n",
    "    surface_area_map_gt = neighbour_code_to_surface_area[neighbour_code_map_gt]\n",
    "    surface_area_map_pred = neighbour_code_to_surface_area[neighbour_code_map_pred]\n",
    "\n",
    "    # create a list of all surface elements with distance and area\n",
    "    distances_gt_to_pred = distmap_pred[borders_gt]\n",
    "    distances_pred_to_gt = distmap_gt[borders_pred]\n",
    "    surfel_areas_gt = surface_area_map_gt[borders_gt]\n",
    "    surfel_areas_pred = surface_area_map_pred[borders_pred]\n",
    "\n",
    "    # sort them by distance\n",
    "    if distances_gt_to_pred.shape != (0,):\n",
    "        sorted_surfels_gt = np.array(sorted(zip(distances_gt_to_pred, surfel_areas_gt)))\n",
    "        distances_gt_to_pred = sorted_surfels_gt[:, 0]\n",
    "        surfel_areas_gt = sorted_surfels_gt[:, 1]\n",
    "\n",
    "    if distances_pred_to_gt.shape != (0,):\n",
    "        sorted_surfels_pred = np.array(sorted(zip(distances_pred_to_gt, surfel_areas_pred)))\n",
    "        distances_pred_to_gt = sorted_surfels_pred[:, 0]\n",
    "        surfel_areas_pred = sorted_surfels_pred[:, 1]\n",
    "\n",
    "    if len(distances_gt_to_pred) > 0:  # pylint: disable=g-explicit-length-test\n",
    "        surfel_areas_cum_gt = np.cumsum(surfel_areas_gt) / np.sum(surfel_areas_gt)\n",
    "        idx = np.searchsorted(surfel_areas_cum_gt, percent/100.0)\n",
    "        perc_distance_gt_to_pred = distances_gt_to_pred[min(idx, len(distances_gt_to_pred)-1)]\n",
    "        max_distance_gt_to_pred = np.max(distances_gt_to_pred)\n",
    "    else:\n",
    "        perc_distance_gt_to_pred = np.Inf\n",
    "        max_distance_gt_to_pred = np.Inf\n",
    "\n",
    "    if len(distances_pred_to_gt) > 0:  # pylint: disable=g-explicit-length-test\n",
    "        surfel_areas_cum_pred = (np.cumsum(surfel_areas_pred) /np.sum(surfel_areas_pred))\n",
    "        idx = np.searchsorted(surfel_areas_cum_pred, percent/100.0)\n",
    "        perc_distance_pred_to_gt = distances_pred_to_gt[min(idx, len(distances_pred_to_gt)-1)]\n",
    "        max_distance_pred_to_gt = np.max(distances_pred_to_gt)\n",
    "    else:\n",
    "        perc_distance_pred_to_gt = np.Inf\n",
    "        max_distance_pred_to_gt = np.Inf\n",
    "\n",
    "    return max(max_distance_gt_to_pred, max_distance_pred_to_gt), max(perc_distance_gt_to_pred, perc_distance_pred_to_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_names_test = ['AMC012', 'AMC006', \n",
    "                  'MUMC094', 'MUMC027', 'MUMC079', 'MUMC052', 'MUMC127', 'MUMC071', 'MUMC038', 'MUMC093', 'MUMC107', \n",
    "                  'MUMC022', 'MUMC114', 'MUMC115', 'MUMC069', 'MUMC130', 'MUMC036', 'MUMC007', 'MUMC059', 'MUMC080', \n",
    "                  'UMCU036', 'UMCU025', 'UMCU008', 'UMCU034']\n",
    "\n",
    "sub_names_emc = ['EMC003', 'EMC004', 'EMC005', 'EMC007', 'EMC008', 'EMC009', 'EMC011', \n",
    "                 'EMC015', 'EMC018', 'EMC020', 'EMC024', 'EMC027', 'EMC029', 'EMC031', \n",
    "                 'EMC032', 'EMC034', 'EMC035', 'EMC036', 'EMC038', 'EMC041', 'EMC042', \n",
    "                 'EMC043', 'EMC045', 'EMC046', 'EMC047', 'EMC048', 'EMC049', 'EMC050', \n",
    "                 'EMC051', 'EMC052', 'EMC054', 'EMC055', 'EMC056', 'EMC057']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "nifti_dirname_GT_test = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\test\\test_GT\"\n",
    "nifti_dirname_GT_t2w = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t2w\\t2w_GT\"\n",
    "nifti_dirname_GT_t1wce = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t1wce\\t1wce_GT\"\n",
    "nifti_dirname_GT_emc = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\emc\\emc_GT\"\n",
    "\n",
    "nifti_dirname_nnunet_test = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\test\\test_nnunet\"\n",
    "nifti_dirname_nnunet_t2w = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t2w\\t2w_nnunet\"\n",
    "nifti_dirname_nnunet_t1wce = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t1wce\\t1wce_nnunet\"\n",
    "nifti_dirname_nnunet_emc = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\emc\\emc_nnunet\"\n",
    "\n",
    "nifti_dirname_nnunet_test_sm = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\test\\test_nnunet_p\"\n",
    "nifti_dirname_nnunet_t2w_sm = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t2w\\t2w_nnunet_p\"\n",
    "nifti_dirname_nnunet_t1wce_sm = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t1wce\\t1wce_nnunet_p\"\n",
    "nifti_dirname_nnunet_emc_sm = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\emc\\emc_nnunet_p\"\n",
    "\n",
    "nifti_dirname_plaqunet_test = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\test\\test_plaqunet\"\n",
    "nifti_dirname_plaqunet_t2w = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t2w\\t2w_plaqunet\"\n",
    "nifti_dirname_plaqunet_t1wce = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t1wce\\t1wce_plaqunet\"\n",
    "nifti_dirname_plaqunet_emc = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\emc\\emc_plaqunet\"\n",
    "\n",
    "nifti_dirname_plaqunet_test_sm = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\test\\test_plaqunet_p\"\n",
    "nifti_dirname_plaqunet_t2w_sm = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t2w\\t2w_plaqunet_p\"\n",
    "nifti_dirname_plaqunet_t1wce_sm=r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t1wce\\t1wce_plaqunet_p\"\n",
    "nifti_dirname_plaqunet_emc_sm = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\emc\\emc_plaqunet_p\"\n",
    "\n",
    "nifti_dirname_plaqumap_test = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\test\\test_plaqumap\"\n",
    "nifti_dirname_plaqumap_t2w = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t2w\\t2w_plaqumap\"\n",
    "nifti_dirname_plaqumap_t1wce = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t1wce\\t1wce_plaqumap\"\n",
    "nifti_dirname_plaqumap_emc = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\emc\\emc_plaqumap\"\n",
    "\n",
    "nifti_dirname_plaqumap_test_sm = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\test\\test_plaqumap_p\"\n",
    "nifti_dirname_plaqumap_t2w_sm = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t2w\\t2w_plaqumap_p\"\n",
    "nifti_dirname_plaqumap_t1wce_sm=r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\t1wce\\t1wce_plaqumap_p\"\n",
    "nifti_dirname_plaqumap_emc_sm = r\"C:\\Users\\E.Lavrova\\Documents\\GitHub\\plaqueuqalp\\res\\nifti_compare\\emc\\emc_plaqumap_p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_df(sub_names, dirname_gt, dirname_pred):\n",
    "\n",
    "    df_scores = []\n",
    "\n",
    "    for sub_name in sub_names:\n",
    "\n",
    "        filename_gt = os.path.join(dirname_gt, sub_name + '.nii.gz')\n",
    "        filename_pred = os.path.join(dirname_pred, sub_name + '.nii.gz')\n",
    "\n",
    "        mask_gt = sitk.ReadImage(filename_gt)\n",
    "        mask_pred = sitk.ReadImage(filename_pred)\n",
    "\n",
    "        mask_gt = sitk.GetArrayFromImage(mask_gt)\n",
    "        mask_pred = sitk.GetArrayFromImage(mask_pred)\n",
    "\n",
    "        rec = {'sub': sub_name} \n",
    "        rec['dsc'] = compute_dice_coef(mask_gt, mask_pred)\n",
    "        rec['jsc'] = compute_jaccard_coef(mask_gt, mask_pred)\n",
    "\n",
    "        hd_max, hd_95 = compute_hausdorf_surf_distance(mask_gt, mask_pred, [2, 0.303030, 0.303030], percent=95)\n",
    "\n",
    "        rec['hd'] = hd_max\n",
    "        rec['hd95'] = hd_95\n",
    "\n",
    "        rec['clDsc'] = clDice(mask_gt, mask_pred)\n",
    "        rec['nsd'] = compute_nsd(mask_gt, mask_pred, tau=1)\n",
    "        rec['apl, cm'] = compute_AddedPathLength(mask_gt, mask_pred, [2, 0.303030, 0.303030])\n",
    "        \n",
    "        vol_gt = np.sum(mask_gt)*0.303030*0.303030*2/1000\n",
    "        vol_pred = np.sum(mask_pred)*0.303030*0.303030*2/1000\n",
    "\n",
    "        rec['vol_gt, ml'] = vol_gt\n",
    "        rec['vol_pred, ml'] = vol_pred\n",
    "\n",
    "        rec['vol_diff, ml'] = vol_gt-vol_pred\n",
    "        rec['abs_vol_diff, ml'] = abs(vol_gt-vol_pred)\n",
    "\n",
    "        df_scores.append(rec)\n",
    "\n",
    "    df_scores = pd.DataFrame(df_scores)\n",
    "    \n",
    "    median_scores, iqr_scores = get_score_median_iqr(df_scores)\n",
    "\n",
    "    return df_scores, median_scores, iqr_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_median_iqr(df_scores):\n",
    "    median_scores = df_scores.median()\n",
    "    iqr_scores = df_scores.quantile(0.75) - df_scores.quantile(0.25)\n",
    "    return median_scores, iqr_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\ipykernel_launcher.py:101: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dd:  0.9370858656856272\n",
      "d1:  0.5452627065435705\n",
      "d2:  0.8278785943245025\n",
      "dd:  0.515556396620515\n",
      "dd:  0.2203022711795197\n",
      "d1:  0.7210682141106652\n",
      "d2:  0.2979320560932429\n",
      "ed:  1.3062246119852325\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test (median)</th>\n",
       "      <th>test (IQR)</th>\n",
       "      <th>t1wce (median)</th>\n",
       "      <th>t1wce (IQR)</th>\n",
       "      <th>t2w (median)</th>\n",
       "      <th>t2w (IQR)</th>\n",
       "      <th>emc (median)</th>\n",
       "      <th>emc (IQR)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dsc</th>\n",
       "      <td>0.915519</td>\n",
       "      <td>0.040110</td>\n",
       "      <td>0.896231</td>\n",
       "      <td>0.121681</td>\n",
       "      <td>0.898951</td>\n",
       "      <td>0.048856</td>\n",
       "      <td>0.872583</td>\n",
       "      <td>0.116781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jsc</th>\n",
       "      <td>0.844221</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>0.811965</td>\n",
       "      <td>0.188310</td>\n",
       "      <td>0.816445</td>\n",
       "      <td>0.080090</td>\n",
       "      <td>0.773968</td>\n",
       "      <td>0.175413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hd</th>\n",
       "      <td>2.534830</td>\n",
       "      <td>5.266332</td>\n",
       "      <td>3.600734</td>\n",
       "      <td>9.575300</td>\n",
       "      <td>2.636793</td>\n",
       "      <td>7.029601</td>\n",
       "      <td>7.061991</td>\n",
       "      <td>4.632097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hd95</th>\n",
       "      <td>1.000840</td>\n",
       "      <td>1.755670</td>\n",
       "      <td>1.302308</td>\n",
       "      <td>4.750351</td>\n",
       "      <td>1.025428</td>\n",
       "      <td>1.765156</td>\n",
       "      <td>4.366740</td>\n",
       "      <td>3.660876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clDsc</th>\n",
       "      <td>0.983624</td>\n",
       "      <td>0.056235</td>\n",
       "      <td>0.992466</td>\n",
       "      <td>0.275004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080770</td>\n",
       "      <td>0.902388</td>\n",
       "      <td>0.130542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nsd</th>\n",
       "      <td>0.972002</td>\n",
       "      <td>0.052348</td>\n",
       "      <td>0.944786</td>\n",
       "      <td>0.215395</td>\n",
       "      <td>0.970522</td>\n",
       "      <td>0.066613</td>\n",
       "      <td>0.874076</td>\n",
       "      <td>0.161613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apl, cm</th>\n",
       "      <td>28.797004</td>\n",
       "      <td>17.001803</td>\n",
       "      <td>36.703324</td>\n",
       "      <td>20.417774</td>\n",
       "      <td>33.406728</td>\n",
       "      <td>10.358106</td>\n",
       "      <td>99.210086</td>\n",
       "      <td>63.337798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_gt, ml</th>\n",
       "      <td>2.230574</td>\n",
       "      <td>0.399586</td>\n",
       "      <td>2.216616</td>\n",
       "      <td>0.437924</td>\n",
       "      <td>2.230574</td>\n",
       "      <td>0.394352</td>\n",
       "      <td>3.624602</td>\n",
       "      <td>1.150365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_pred, ml</th>\n",
       "      <td>2.135257</td>\n",
       "      <td>0.428282</td>\n",
       "      <td>2.166754</td>\n",
       "      <td>0.796784</td>\n",
       "      <td>2.131768</td>\n",
       "      <td>0.431266</td>\n",
       "      <td>2.891271</td>\n",
       "      <td>0.946371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_diff, ml</th>\n",
       "      <td>0.134619</td>\n",
       "      <td>0.271212</td>\n",
       "      <td>-0.077043</td>\n",
       "      <td>0.354728</td>\n",
       "      <td>0.030854</td>\n",
       "      <td>0.305922</td>\n",
       "      <td>0.692285</td>\n",
       "      <td>0.522038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_vol_diff, ml</th>\n",
       "      <td>0.154821</td>\n",
       "      <td>0.109688</td>\n",
       "      <td>0.219191</td>\n",
       "      <td>0.505233</td>\n",
       "      <td>0.170615</td>\n",
       "      <td>0.182552</td>\n",
       "      <td>0.692285</td>\n",
       "      <td>0.522038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  test (median)  test (IQR)  t1wce (median)  t1wce (IQR)  \\\n",
       "dsc                    0.915519    0.040110        0.896231     0.121681   \n",
       "jsc                    0.844221    0.067904        0.811965     0.188310   \n",
       "hd                     2.534830    5.266332        3.600734     9.575300   \n",
       "hd95                   1.000840    1.755670        1.302308     4.750351   \n",
       "clDsc                  0.983624    0.056235        0.992466     0.275004   \n",
       "nsd                    0.972002    0.052348        0.944786     0.215395   \n",
       "apl, cm               28.797004   17.001803       36.703324    20.417774   \n",
       "vol_gt, ml             2.230574    0.399586        2.216616     0.437924   \n",
       "vol_pred, ml           2.135257    0.428282        2.166754     0.796784   \n",
       "vol_diff, ml           0.134619    0.271212       -0.077043     0.354728   \n",
       "abs_vol_diff, ml       0.154821    0.109688        0.219191     0.505233   \n",
       "\n",
       "                  t2w (median)  t2w (IQR)  emc (median)  emc (IQR)  \n",
       "dsc                   0.898951   0.048856      0.872583   0.116781  \n",
       "jsc                   0.816445   0.080090      0.773968   0.175413  \n",
       "hd                    2.636793   7.029601      7.061991   4.632097  \n",
       "hd95                  1.025428   1.765156      4.366740   3.660876  \n",
       "clDsc                 1.000000   0.080770      0.902388   0.130542  \n",
       "nsd                   0.970522   0.066613      0.874076   0.161613  \n",
       "apl, cm              33.406728  10.358106     99.210086  63.337798  \n",
       "vol_gt, ml            2.230574   0.394352      3.624602   1.150365  \n",
       "vol_pred, ml          2.131768   0.431266      2.891271   0.946371  \n",
       "vol_diff, ml          0.030854   0.305922      0.692285   0.522038  \n",
       "abs_vol_diff, ml      0.170615   0.182552      0.692285   0.522038  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores_nnunet_test, median_scores_nnunet_test, iqr_scores_nnunet_test = get_scores_df(sub_names_test, \n",
    "                                                                                         nifti_dirname_GT_test, \n",
    "                                                                                         nifti_dirname_nnunet_test)\n",
    "df_scores_nnunet_t1wce, median_scores_nnunet_t1wce, iqr_scores_nnunet_t1wce = get_scores_df(sub_names_test, \n",
    "                                                                                            nifti_dirname_GT_t1wce, \n",
    "                                                                                            nifti_dirname_nnunet_t1wce)\n",
    "df_scores_nnunet_t2w, median_scores_nnunet_t2w, iqr_scores_nnunet_t2w = get_scores_df(sub_names_test, \n",
    "                                                                                      nifti_dirname_GT_t2w, \n",
    "                                                                                      nifti_dirname_nnunet_t2w)\n",
    "df_scores_nnunet_emc, median_scores_nnunet_emc, iqr_scores_nnunet_emc = get_scores_df(sub_names_emc, \n",
    "                                                                                      nifti_dirname_GT_emc, \n",
    "                                                                                      nifti_dirname_nnunet_emc)\n",
    "\n",
    "summary_scores_nnunet = pd.concat([median_scores_nnunet_test, iqr_scores_nnunet_test, \n",
    "                                   median_scores_nnunet_t1wce, iqr_scores_nnunet_t1wce, \n",
    "                                   median_scores_nnunet_t2w, iqr_scores_nnunet_t2w, \n",
    "                                   median_scores_nnunet_emc, iqr_scores_nnunet_emc\n",
    "                                  ], axis=1)\n",
    "summary_scores_nnunet.columns = ['test (median)', 'test (IQR)', 't1wce (median)', 't1wce (IQR)', \n",
    "                                 't2w (median)', 't2w (IQR)', 'emc (median)', 'emc (IQR)']\n",
    "\n",
    "\n",
    "print ('dd: ', icc(np.column_stack((df_scores_nnunet_test['vol_gt, ml'], df_scores_nnunet_test['vol_pred, ml'])), \n",
    "                   icc_type='ICC(2,k)'))\n",
    "print ('d1: ', icc(np.column_stack((df_scores_nnunet_t1wce['vol_gt, ml'], df_scores_nnunet_t1wce['vol_pred, ml'])), \n",
    "                   icc_type='ICC(2,k)'))\n",
    "print ('d2: ', icc(np.column_stack((df_scores_nnunet_t2w['vol_gt, ml'], df_scores_nnunet_t2w['vol_pred, ml'])), \n",
    "                   icc_type='ICC(2,k)'))\n",
    "print ('dd: ', icc(np.column_stack((df_scores_nnunet_emc['vol_gt, ml'], df_scores_nnunet_emc['vol_pred, ml'])), \n",
    "                   icc_type='ICC(2,k)'))\n",
    "\n",
    "print ('dd: ', mean_squared_error(df_scores_nnunet_test['vol_gt, ml'], df_scores_nnunet_test['vol_pred, ml'], \n",
    "                                  squared=False))\n",
    "print ('d1: ', mean_squared_error(df_scores_nnunet_t1wce['vol_gt, ml'],df_scores_nnunet_t1wce['vol_pred, ml'], \n",
    "                                  squared=False))\n",
    "print ('d2: ', mean_squared_error(df_scores_nnunet_t2w['vol_gt, ml'], df_scores_nnunet_t2w['vol_pred, ml'], \n",
    "                                  squared=False))\n",
    "print ('ed: ', mean_squared_error(df_scores_nnunet_emc['vol_gt, ml'], df_scores_nnunet_emc['vol_pred, ml'], \n",
    "                                  squared=False))\n",
    "\n",
    "summary_scores_nnunet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\ipykernel_launcher.py:101: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dd:  0.8855167230246309\n",
      "d1:  0.7398457351078757\n",
      "d2:  0.849928780053147\n",
      "dd:  0.7519983465526479\n",
      "dd:  0.2782159968007799\n",
      "d1:  0.44278103341836883\n",
      "d2:  0.2833773139553194\n",
      "ed:  0.8688829169473344\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test (median)</th>\n",
       "      <th>test (IQR)</th>\n",
       "      <th>t1wce (median)</th>\n",
       "      <th>t1wce (IQR)</th>\n",
       "      <th>t2w (median)</th>\n",
       "      <th>t2w (IQR)</th>\n",
       "      <th>emc (median)</th>\n",
       "      <th>emc (IQR)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dsc</th>\n",
       "      <td>0.918985</td>\n",
       "      <td>0.049563</td>\n",
       "      <td>0.886114</td>\n",
       "      <td>0.132073</td>\n",
       "      <td>0.897172</td>\n",
       "      <td>0.050207</td>\n",
       "      <td>0.867757</td>\n",
       "      <td>0.091948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jsc</th>\n",
       "      <td>0.850111</td>\n",
       "      <td>0.082718</td>\n",
       "      <td>0.795519</td>\n",
       "      <td>0.200828</td>\n",
       "      <td>0.813525</td>\n",
       "      <td>0.082103</td>\n",
       "      <td>0.766398</td>\n",
       "      <td>0.140128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hd</th>\n",
       "      <td>2.278981</td>\n",
       "      <td>1.341173</td>\n",
       "      <td>3.487910</td>\n",
       "      <td>6.134541</td>\n",
       "      <td>2.518235</td>\n",
       "      <td>4.761909</td>\n",
       "      <td>7.651124</td>\n",
       "      <td>4.830383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hd95</th>\n",
       "      <td>0.933677</td>\n",
       "      <td>1.171124</td>\n",
       "      <td>1.530153</td>\n",
       "      <td>4.751841</td>\n",
       "      <td>1.249425</td>\n",
       "      <td>3.082536</td>\n",
       "      <td>4.188599</td>\n",
       "      <td>3.605129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clDsc</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017120</td>\n",
       "      <td>0.977841</td>\n",
       "      <td>0.190239</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.077950</td>\n",
       "      <td>0.889349</td>\n",
       "      <td>0.131869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nsd</th>\n",
       "      <td>0.970915</td>\n",
       "      <td>0.053144</td>\n",
       "      <td>0.932086</td>\n",
       "      <td>0.221638</td>\n",
       "      <td>0.962174</td>\n",
       "      <td>0.083859</td>\n",
       "      <td>0.884554</td>\n",
       "      <td>0.106791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apl, cm</th>\n",
       "      <td>31.276338</td>\n",
       "      <td>17.910892</td>\n",
       "      <td>35.206541</td>\n",
       "      <td>23.273599</td>\n",
       "      <td>33.223074</td>\n",
       "      <td>12.382895</td>\n",
       "      <td>87.612313</td>\n",
       "      <td>55.656454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_gt, ml</th>\n",
       "      <td>2.230574</td>\n",
       "      <td>0.399586</td>\n",
       "      <td>2.216616</td>\n",
       "      <td>0.437924</td>\n",
       "      <td>2.230574</td>\n",
       "      <td>0.394352</td>\n",
       "      <td>3.624602</td>\n",
       "      <td>1.150365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_pred, ml</th>\n",
       "      <td>2.111107</td>\n",
       "      <td>0.438704</td>\n",
       "      <td>2.193017</td>\n",
       "      <td>0.802340</td>\n",
       "      <td>2.087232</td>\n",
       "      <td>0.389072</td>\n",
       "      <td>2.902749</td>\n",
       "      <td>0.978097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_diff, ml</th>\n",
       "      <td>0.160422</td>\n",
       "      <td>0.262396</td>\n",
       "      <td>-0.040863</td>\n",
       "      <td>0.408769</td>\n",
       "      <td>0.024885</td>\n",
       "      <td>0.353856</td>\n",
       "      <td>0.645086</td>\n",
       "      <td>0.303076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_vol_diff, ml</th>\n",
       "      <td>0.198255</td>\n",
       "      <td>0.210743</td>\n",
       "      <td>0.225160</td>\n",
       "      <td>0.463084</td>\n",
       "      <td>0.167309</td>\n",
       "      <td>0.214646</td>\n",
       "      <td>0.645086</td>\n",
       "      <td>0.303076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  test (median)  test (IQR)  t1wce (median)  t1wce (IQR)  \\\n",
       "dsc                    0.918985    0.049563        0.886114     0.132073   \n",
       "jsc                    0.850111    0.082718        0.795519     0.200828   \n",
       "hd                     2.278981    1.341173        3.487910     6.134541   \n",
       "hd95                   0.933677    1.171124        1.530153     4.751841   \n",
       "clDsc                  1.000000    0.017120        0.977841     0.190239   \n",
       "nsd                    0.970915    0.053144        0.932086     0.221638   \n",
       "apl, cm               31.276338   17.910892       35.206541    23.273599   \n",
       "vol_gt, ml             2.230574    0.399586        2.216616     0.437924   \n",
       "vol_pred, ml           2.111107    0.438704        2.193017     0.802340   \n",
       "vol_diff, ml           0.160422    0.262396       -0.040863     0.408769   \n",
       "abs_vol_diff, ml       0.198255    0.210743        0.225160     0.463084   \n",
       "\n",
       "                  t2w (median)  t2w (IQR)  emc (median)  emc (IQR)  \n",
       "dsc                   0.897172   0.050207      0.867757   0.091948  \n",
       "jsc                   0.813525   0.082103      0.766398   0.140128  \n",
       "hd                    2.518235   4.761909      7.651124   4.830383  \n",
       "hd95                  1.249425   3.082536      4.188599   3.605129  \n",
       "clDsc                 1.000000   0.077950      0.889349   0.131869  \n",
       "nsd                   0.962174   0.083859      0.884554   0.106791  \n",
       "apl, cm              33.223074  12.382895     87.612313  55.656454  \n",
       "vol_gt, ml            2.230574   0.394352      3.624602   1.150365  \n",
       "vol_pred, ml          2.087232   0.389072      2.902749   0.978097  \n",
       "vol_diff, ml          0.024885   0.353856      0.645086   0.303076  \n",
       "abs_vol_diff, ml      0.167309   0.214646      0.645086   0.303076  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores_plaqunet_test, median_scores_plaqunet_test, iqr_scores_plaqunet_test = get_scores_df(sub_names_test, \n",
    "                                                                                         nifti_dirname_GT_test, \n",
    "                                                                                         nifti_dirname_plaqunet_test)\n",
    "df_scores_plaqunet_t1wce, median_scores_plaqunet_t1wce, iqr_scores_plaqunet_t1wce = get_scores_df(sub_names_test, \n",
    "                                                                                            nifti_dirname_GT_t1wce, \n",
    "                                                                                            nifti_dirname_plaqunet_t1wce)\n",
    "df_scores_plaqunet_t2w, median_scores_plaqunet_t2w, iqr_scores_plaqunet_t2w = get_scores_df(sub_names_test, \n",
    "                                                                                      nifti_dirname_GT_t2w, \n",
    "                                                                                      nifti_dirname_plaqunet_t2w)\n",
    "df_scores_plaqunet_emc, median_scores_plaqunet_emc, iqr_scores_plaqunet_emc = get_scores_df(sub_names_emc, \n",
    "                                                                                      nifti_dirname_GT_emc, \n",
    "                                                                                      nifti_dirname_plaqunet_emc)\n",
    "\n",
    "summary_scores_plaqunet = pd.concat([median_scores_plaqunet_test, iqr_scores_plaqunet_test, \n",
    "                                   median_scores_plaqunet_t1wce, iqr_scores_plaqunet_t1wce, \n",
    "                                   median_scores_plaqunet_t2w, iqr_scores_plaqunet_t2w, \n",
    "                                   median_scores_plaqunet_emc, iqr_scores_plaqunet_emc\n",
    "                                  ], axis=1)\n",
    "summary_scores_plaqunet.columns = ['test (median)', 'test (IQR)', 't1wce (median)', 't1wce (IQR)', \n",
    "                                 't2w (median)', 't2w (IQR)', 'emc (median)', 'emc (IQR)']\n",
    "\n",
    "\n",
    "print ('dd: ', icc(np.column_stack((df_scores_plaqunet_test['vol_gt, ml'], df_scores_plaqunet_test['vol_pred, ml'])), \n",
    "                   icc_type='ICC(2,k)'))\n",
    "print ('d1: ', icc(np.column_stack((df_scores_plaqunet_t1wce['vol_gt, ml'], df_scores_plaqunet_t1wce['vol_pred, ml'])), \n",
    "                   icc_type='ICC(2,k)'))\n",
    "print ('d2: ', icc(np.column_stack((df_scores_plaqunet_t2w['vol_gt, ml'], df_scores_plaqunet_t2w['vol_pred, ml'])), \n",
    "                   icc_type='ICC(2,k)'))\n",
    "print ('dd: ', icc(np.column_stack((df_scores_plaqunet_emc['vol_gt, ml'], df_scores_plaqunet_emc['vol_pred, ml'])), \n",
    "                   icc_type='ICC(2,k)'))\n",
    "\n",
    "print ('dd: ', mean_squared_error(df_scores_plaqunet_test['vol_gt, ml'], df_scores_plaqunet_test['vol_pred, ml'], \n",
    "                                  squared=False))\n",
    "print ('d1: ', mean_squared_error(df_scores_plaqunet_t1wce['vol_gt, ml'],df_scores_plaqunet_t1wce['vol_pred, ml'], \n",
    "                                  squared=False))\n",
    "print ('d2: ', mean_squared_error(df_scores_plaqunet_t2w['vol_gt, ml'], df_scores_plaqunet_t2w['vol_pred, ml'], \n",
    "                                  squared=False))\n",
    "print ('ed: ', mean_squared_error(df_scores_plaqunet_emc['vol_gt, ml'], df_scores_plaqunet_emc['vol_pred, ml'], \n",
    "                                  squared=False))\n",
    "\n",
    "summary_scores_plaqunet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\ipykernel_launcher.py:101: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dd:  0.9095519373699396\n",
      "d1:  0.7369483230271406\n",
      "d2:  0.8585896937768533\n",
      "dd:  0.8076071130081085\n",
      "dd:  0.24130216125400636\n",
      "d1:  0.45076071275785423\n",
      "d2:  0.27376673802847973\n",
      "ed:  0.7252523906087737\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test (median)</th>\n",
       "      <th>test (IQR)</th>\n",
       "      <th>t1wce (median)</th>\n",
       "      <th>t1wce (IQR)</th>\n",
       "      <th>t2w (median)</th>\n",
       "      <th>t2w (IQR)</th>\n",
       "      <th>emc (median)</th>\n",
       "      <th>emc (IQR)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dsc</th>\n",
       "      <td>0.916972</td>\n",
       "      <td>0.033133</td>\n",
       "      <td>0.891757</td>\n",
       "      <td>0.113594</td>\n",
       "      <td>0.897665</td>\n",
       "      <td>0.050851</td>\n",
       "      <td>0.894006</td>\n",
       "      <td>0.067375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jsc</th>\n",
       "      <td>0.846674</td>\n",
       "      <td>0.055896</td>\n",
       "      <td>0.804656</td>\n",
       "      <td>0.174980</td>\n",
       "      <td>0.814423</td>\n",
       "      <td>0.083896</td>\n",
       "      <td>0.808322</td>\n",
       "      <td>0.106654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hd</th>\n",
       "      <td>2.185180</td>\n",
       "      <td>2.301245</td>\n",
       "      <td>3.594206</td>\n",
       "      <td>6.260535</td>\n",
       "      <td>2.540063</td>\n",
       "      <td>5.934103</td>\n",
       "      <td>7.494247</td>\n",
       "      <td>4.645600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hd95</th>\n",
       "      <td>0.933677</td>\n",
       "      <td>1.259802</td>\n",
       "      <td>1.681668</td>\n",
       "      <td>5.609319</td>\n",
       "      <td>1.152355</td>\n",
       "      <td>1.990329</td>\n",
       "      <td>4.468687</td>\n",
       "      <td>3.743264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clDsc</th>\n",
       "      <td>0.996124</td>\n",
       "      <td>0.045148</td>\n",
       "      <td>0.987482</td>\n",
       "      <td>0.267293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.093711</td>\n",
       "      <td>0.907252</td>\n",
       "      <td>0.140077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nsd</th>\n",
       "      <td>0.972961</td>\n",
       "      <td>0.042005</td>\n",
       "      <td>0.936623</td>\n",
       "      <td>0.207302</td>\n",
       "      <td>0.958213</td>\n",
       "      <td>0.067322</td>\n",
       "      <td>0.894854</td>\n",
       "      <td>0.082482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apl, cm</th>\n",
       "      <td>28.576619</td>\n",
       "      <td>10.693275</td>\n",
       "      <td>36.078899</td>\n",
       "      <td>19.256160</td>\n",
       "      <td>32.470091</td>\n",
       "      <td>11.772245</td>\n",
       "      <td>78.383682</td>\n",
       "      <td>60.100890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_gt, ml</th>\n",
       "      <td>2.230574</td>\n",
       "      <td>0.399586</td>\n",
       "      <td>2.216616</td>\n",
       "      <td>0.437924</td>\n",
       "      <td>2.230574</td>\n",
       "      <td>0.394352</td>\n",
       "      <td>3.624602</td>\n",
       "      <td>1.150365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_pred, ml</th>\n",
       "      <td>2.257112</td>\n",
       "      <td>0.379476</td>\n",
       "      <td>2.351602</td>\n",
       "      <td>0.764048</td>\n",
       "      <td>2.307158</td>\n",
       "      <td>0.344214</td>\n",
       "      <td>3.174741</td>\n",
       "      <td>0.765839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_diff, ml</th>\n",
       "      <td>-0.026171</td>\n",
       "      <td>0.283884</td>\n",
       "      <td>-0.210468</td>\n",
       "      <td>0.416574</td>\n",
       "      <td>-0.110376</td>\n",
       "      <td>0.328512</td>\n",
       "      <td>0.471992</td>\n",
       "      <td>0.300413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_vol_diff, ml</th>\n",
       "      <td>0.145362</td>\n",
       "      <td>0.128191</td>\n",
       "      <td>0.313590</td>\n",
       "      <td>0.376308</td>\n",
       "      <td>0.198714</td>\n",
       "      <td>0.172084</td>\n",
       "      <td>0.471992</td>\n",
       "      <td>0.300413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  test (median)  test (IQR)  t1wce (median)  t1wce (IQR)  \\\n",
       "dsc                    0.916972    0.033133        0.891757     0.113594   \n",
       "jsc                    0.846674    0.055896        0.804656     0.174980   \n",
       "hd                     2.185180    2.301245        3.594206     6.260535   \n",
       "hd95                   0.933677    1.259802        1.681668     5.609319   \n",
       "clDsc                  0.996124    0.045148        0.987482     0.267293   \n",
       "nsd                    0.972961    0.042005        0.936623     0.207302   \n",
       "apl, cm               28.576619   10.693275       36.078899    19.256160   \n",
       "vol_gt, ml             2.230574    0.399586        2.216616     0.437924   \n",
       "vol_pred, ml           2.257112    0.379476        2.351602     0.764048   \n",
       "vol_diff, ml          -0.026171    0.283884       -0.210468     0.416574   \n",
       "abs_vol_diff, ml       0.145362    0.128191        0.313590     0.376308   \n",
       "\n",
       "                  t2w (median)  t2w (IQR)  emc (median)  emc (IQR)  \n",
       "dsc                   0.897665   0.050851      0.894006   0.067375  \n",
       "jsc                   0.814423   0.083896      0.808322   0.106654  \n",
       "hd                    2.540063   5.934103      7.494247   4.645600  \n",
       "hd95                  1.152355   1.990329      4.468687   3.743264  \n",
       "clDsc                 1.000000   0.093711      0.907252   0.140077  \n",
       "nsd                   0.958213   0.067322      0.894854   0.082482  \n",
       "apl, cm              32.470091  11.772245     78.383682  60.100890  \n",
       "vol_gt, ml            2.230574   0.394352      3.624602   1.150365  \n",
       "vol_pred, ml          2.307158   0.344214      3.174741   0.765839  \n",
       "vol_diff, ml         -0.110376   0.328512      0.471992   0.300413  \n",
       "abs_vol_diff, ml      0.198714   0.172084      0.471992   0.300413  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores_plaqumap_test, median_scores_plaqumap_test, iqr_scores_plaqumap_test = get_scores_df(sub_names_test, \n",
    "                                                                                         nifti_dirname_GT_test, \n",
    "                                                                                         nifti_dirname_plaqumap_test)\n",
    "df_scores_plaqumap_t1wce, median_scores_plaqumap_t1wce, iqr_scores_plaqumap_t1wce = get_scores_df(sub_names_test, \n",
    "                                                                                            nifti_dirname_GT_t1wce, \n",
    "                                                                                            nifti_dirname_plaqumap_t1wce)\n",
    "df_scores_plaqumap_t2w, median_scores_plaqumap_t2w, iqr_scores_plaqumap_t2w = get_scores_df(sub_names_test, \n",
    "                                                                                      nifti_dirname_GT_t2w, \n",
    "                                                                                      nifti_dirname_plaqumap_t2w)\n",
    "df_scores_plaqumap_emc, median_scores_plaqumap_emc, iqr_scores_plaqumap_emc = get_scores_df(sub_names_emc, \n",
    "                                                                                      nifti_dirname_GT_emc, \n",
    "                                                                                      nifti_dirname_plaqumap_emc)\n",
    "\n",
    "summary_scores_plaqumap = pd.concat([median_scores_plaqumap_test, iqr_scores_plaqumap_test, \n",
    "                                   median_scores_plaqumap_t1wce, iqr_scores_plaqumap_t1wce, \n",
    "                                   median_scores_plaqumap_t2w, iqr_scores_plaqumap_t2w, \n",
    "                                   median_scores_plaqumap_emc, iqr_scores_plaqumap_emc\n",
    "                                  ], axis=1)\n",
    "summary_scores_plaqumap.columns = ['test (median)', 'test (IQR)', 't1wce (median)', 't1wce (IQR)', \n",
    "                                 't2w (median)', 't2w (IQR)', 'emc (median)', 'emc (IQR)']\n",
    "\n",
    "\n",
    "print ('dd: ', icc(np.column_stack((df_scores_plaqumap_test['vol_gt, ml'], df_scores_plaqumap_test['vol_pred, ml'])), \n",
    "                   icc_type='ICC(2,k)'))\n",
    "print ('d1: ', icc(np.column_stack((df_scores_plaqumap_t1wce['vol_gt, ml'], df_scores_plaqumap_t1wce['vol_pred, ml'])), \n",
    "                   icc_type='ICC(2,k)'))\n",
    "print ('d2: ', icc(np.column_stack((df_scores_plaqumap_t2w['vol_gt, ml'], df_scores_plaqumap_t2w['vol_pred, ml'])), \n",
    "                   icc_type='ICC(2,k)'))\n",
    "print ('dd: ', icc(np.column_stack((df_scores_plaqumap_emc['vol_gt, ml'], df_scores_plaqumap_emc['vol_pred, ml'])), \n",
    "                   icc_type='ICC(2,k)'))\n",
    "\n",
    "print ('dd: ', mean_squared_error(df_scores_plaqumap_test['vol_gt, ml'], df_scores_plaqumap_test['vol_pred, ml'], \n",
    "                                  squared=False))\n",
    "print ('d1: ', mean_squared_error(df_scores_plaqumap_t1wce['vol_gt, ml'],df_scores_plaqumap_t1wce['vol_pred, ml'], \n",
    "                                  squared=False))\n",
    "print ('d2: ', mean_squared_error(df_scores_plaqumap_t2w['vol_gt, ml'], df_scores_plaqumap_t2w['vol_pred, ml'], \n",
    "                                  squared=False))\n",
    "print ('ed: ', mean_squared_error(df_scores_plaqumap_emc['vol_gt, ml'], df_scores_plaqumap_emc['vol_pred, ml'], \n",
    "                                  squared=False))\n",
    "\n",
    "summary_scores_plaqumap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_scores(x_1, x_2):\n",
    "    U, p = stats.wilcoxon(x_1, x_2, zero_method = 'wilcox')\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsc\n",
      "plaq-u-net vs plaq-uncertainty-net:  6.639428259340563e-06\n",
      "nnUNet vs plaq-uncertainty-net:  5.711344941487451e-07\n",
      "jsc\n",
      "plaq-u-net vs plaq-uncertainty-net:  6.124988255052021e-06\n",
      "nnUNet vs plaq-uncertainty-net:  6.484785739349568e-07\n",
      "hd\n",
      "plaq-u-net vs plaq-uncertainty-net:  0.6891349940127396\n",
      "nnUNet vs plaq-uncertainty-net:  0.5386680307064231\n",
      "hd95\n",
      "plaq-u-net vs plaq-uncertainty-net:  0.1631073882292975\n",
      "nnUNet vs plaq-uncertainty-net:  0.27438136433460003\n",
      "clDsc\n",
      "plaq-u-net vs plaq-uncertainty-net:  0.03430851926047363\n",
      "nnUNet vs plaq-uncertainty-net:  0.10807264392253305\n",
      "nsd\n",
      "plaq-u-net vs plaq-uncertainty-net:  0.0005030241677042235\n",
      "nnUNet vs plaq-uncertainty-net:  1.8744405365035262e-05\n",
      "apl, cm\n",
      "plaq-u-net vs plaq-uncertainty-net:  6.240101232063704e-07\n",
      "nnUNet vs plaq-uncertainty-net:  1.7560560082939785e-06\n",
      "vol_diff, ml\n",
      "plaq-u-net vs plaq-uncertainty-net:  4.371614103328839e-07\n",
      "nnUNet vs plaq-uncertainty-net:  5.225915161937346e-07\n",
      "abs_vol_diff, ml\n",
      "plaq-u-net vs plaq-uncertainty-net:  4.371614103328839e-07\n",
      "nnUNet vs plaq-uncertainty-net:  5.225915161937346e-07\n"
     ]
    }
   ],
   "source": [
    "print ('dsc')\n",
    "p = compare_scores(df_scores_plaqumap_emc['dsc'], df_scores_nnunet_emc['dsc'])\n",
    "print ('plaq-u-net vs plaq-uncertainty-net: ', p)\n",
    "p = compare_scores(df_scores_plaqumap_emc['dsc'], df_scores_plaqunet_emc['dsc'])\n",
    "print ('nnUNet vs plaq-uncertainty-net: ', p)\n",
    "\n",
    "print ('jsc')\n",
    "p = compare_scores(df_scores_plaqumap_emc['jsc'], df_scores_nnunet_emc['jsc'])\n",
    "print ('plaq-u-net vs plaq-uncertainty-net: ', p)\n",
    "p = compare_scores(df_scores_plaqumap_emc['jsc'], df_scores_plaqunet_emc['jsc'])\n",
    "print ('nnUNet vs plaq-uncertainty-net: ', p)\n",
    "\n",
    "print ('hd')\n",
    "p = compare_scores(df_scores_plaqumap_emc['hd'], df_scores_nnunet_emc['hd'])\n",
    "print ('plaq-u-net vs plaq-uncertainty-net: ', p)\n",
    "p = compare_scores(df_scores_plaqumap_emc['hd'], df_scores_plaqunet_emc['hd'])\n",
    "print ('nnUNet vs plaq-uncertainty-net: ', p)\n",
    "\n",
    "print ('hd95')\n",
    "p = compare_scores(df_scores_plaqumap_emc['hd95'], df_scores_nnunet_emc['hd95'])\n",
    "print ('plaq-u-net vs plaq-uncertainty-net: ', p)\n",
    "p = compare_scores(df_scores_plaqumap_emc['hd95'], df_scores_plaqunet_emc['hd95'])\n",
    "print ('nnUNet vs plaq-uncertainty-net: ', p)\n",
    "\n",
    "print ('clDsc')\n",
    "p = compare_scores(df_scores_plaqumap_emc['clDsc'], df_scores_nnunet_emc['clDsc'])\n",
    "print ('plaq-u-net vs plaq-uncertainty-net: ', p)\n",
    "p = compare_scores(df_scores_plaqumap_emc['clDsc'], df_scores_plaqunet_emc['clDsc'])\n",
    "print ('nnUNet vs plaq-uncertainty-net: ', p)\n",
    "\n",
    "print ('nsd')\n",
    "p = compare_scores(df_scores_plaqumap_emc['nsd'], df_scores_nnunet_emc['nsd'])\n",
    "print ('plaq-u-net vs plaq-uncertainty-net: ', p)\n",
    "p = compare_scores(df_scores_plaqumap_emc['nsd'], df_scores_plaqunet_emc['nsd'])\n",
    "print ('nnUNet vs plaq-uncertainty-net: ', p)\n",
    "\n",
    "print ('apl, cm')\n",
    "p = compare_scores(df_scores_plaqumap_emc['apl, cm'], df_scores_nnunet_emc['apl, cm'])\n",
    "print ('plaq-u-net vs plaq-uncertainty-net: ', p)\n",
    "p = compare_scores(df_scores_plaqumap_emc['apl, cm'], df_scores_plaqunet_emc['apl, cm'])\n",
    "print ('nnUNet vs plaq-uncertainty-net: ', p)\n",
    "\n",
    "print ('vol_diff, ml')\n",
    "p = compare_scores(df_scores_plaqumap_emc['vol_diff, ml'], df_scores_nnunet_emc['vol_diff, ml'])\n",
    "print ('plaq-u-net vs plaq-uncertainty-net: ', p)\n",
    "p = compare_scores(df_scores_plaqumap_emc['vol_diff, ml'], df_scores_plaqunet_emc['vol_diff, ml'])\n",
    "print ('nnUNet vs plaq-uncertainty-net: ', p)\n",
    "\n",
    "print ('abs_vol_diff, ml')\n",
    "p = compare_scores(df_scores_plaqumap_emc['abs_vol_diff, ml'], df_scores_nnunet_emc['abs_vol_diff, ml'])\n",
    "print ('plaq-u-net vs plaq-uncertainty-net: ', p)\n",
    "p = compare_scores(df_scores_plaqumap_emc['abs_vol_diff, ml'], df_scores_plaqunet_emc['abs_vol_diff, ml'])\n",
    "print ('nnUNet vs plaq-uncertainty-net: ', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_area_diameter(mask):\n",
    "    mask_labeled = label(mask)\n",
    "    regions = regionprops(mask_labeled)\n",
    "    area_max = 0\n",
    "    diameter_max = 0\n",
    "    for r in regions:\n",
    "        diameter = r.axis_major_length\n",
    "        area = r.area\n",
    "        if area>area_max:\n",
    "            area_max = area\n",
    "            diameter_max = diameter\n",
    "    return area_max, diameter_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2Dscores(metrics_df, dir_gt, dir_pred):\n",
    "    areas = []\n",
    "    diameters = []\n",
    "    dscs = []\n",
    "    for filename in metrics_df.filename:\n",
    "        item = os.path.split(filename)[-1]\n",
    "        filename_gt = os.path.join(dir_gt,item)\n",
    "        filename_pred = os.path.join(dir_pred,item)\n",
    "        nii_gt = nib.load(filename_gt)\n",
    "        nii_pred = nib.load(filename_pred)\n",
    "        array_gt = nii_gt.get_fdata()\n",
    "        array_pred = nii_pred.get_fdata()\n",
    "        for i in range(array_gt.shape[2]):\n",
    "            dsc = calculate_dice(array_gt[..., i], array_pred[..., i])\n",
    "            a, d = calculate_area_diameter(array_gt[..., i])\n",
    "            areas.append(a*0.303030*0.303030)\n",
    "            diameters.append(d)\n",
    "            dscs.append(dsc)\n",
    "    return areas, diameters, dscs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median_percentile_area_dice(areas_list, dscs_list, \n",
    "                                    bin_area_min = 25, bin_area_max = 200, bin_area_step = 25, ci = 90):\n",
    "    \n",
    "    bin_areas = np.arange(bin_area_min, bin_area_max+1, bin_area_step)\n",
    "    \n",
    "    bin_dscs = []\n",
    "    for j in range (0, len(bin_areas)-1):\n",
    "        bin1_dscs = []\n",
    "        for i in range(0, len(areas_list)):\n",
    "            if (areas_list[i]>bin_areas[j]) and (areas_list[i]<=bin_areas[j+1]):\n",
    "                bin1_dscs.append(dscs_list[i])\n",
    "        bin_dscs.append(bin1_dscs)\n",
    "\n",
    "    bin_dscs_median = []\n",
    "    bin_dscs_low = []\n",
    "    bin_dscs_high = []\n",
    "    p_low = (100-ci)/2\n",
    "    p_high = 100-p_low\n",
    "    for i in range (0, len(bin_dscs)):\n",
    "        bin_dscs_median.append(np.nanmedian(bin_dscs[i]))\n",
    "        bin_dscs_low.append(np.percentile(bin_dscs[i], p_low))\n",
    "        bin_dscs_high.append(np.percentile(bin_dscs[i], p_high))\n",
    "        \n",
    "    return bin_areas, bin_dscs_median, bin_dscs_low, bin_dscs_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_dice_area(scores_df_1, scores_df_2, scores_df_3, scores_df_4, \n",
    "                      dirname_gt_1, dirname_gt_2, dirname_gt_3, dirname_gt_4,\n",
    "                      dirname_1, dirname_2, dirname_3, dirname_4):\n",
    "    \n",
    "    areas_test, diameters_test, dscs_test = get_2Dscores(scores_df_1, dirname_gt_1, dirname_1)\n",
    "    areas_t2w, diameters_t2w, dscs_t2w = get_2Dscores(scores_df_2, dirname_gt_2, dirname_2)\n",
    "    areas_t1wce, diameters_t1wce, dscs_t1wce = get_2Dscores(scores_df_3, dirname_gt_3, dirname_3)\n",
    "    areas_emc, diameters_emc, dscs_emc = get_2Dscores(scores_df_4, dirname_gt_4, dirname_4)\n",
    "\n",
    "    plt.figure(figsize=(17, 4))\n",
    "    plt.subplot(141)\n",
    "    xy = np.vstack([areas_test, dscs_test])\n",
    "    z = gaussian_kde(xy)(xy)\n",
    "    plt.scatter(areas_test, dscs_test, c=z, s=50, edgecolors='k')\n",
    "    plt.xlabel('CA area, mm$^{2}$')\n",
    "    plt.ylabel('DSC')\n",
    "    plt.title('T1w')\n",
    "    plt.subplot(142)\n",
    "    xy = np.vstack([areas_t2w, dscs_t2w])\n",
    "    z = gaussian_kde(xy)(xy)\n",
    "    plt.scatter(areas_t2w, dscs_t2w, c=z, s=50, edgecolors='k')\n",
    "    plt.xlabel('CA area, mm$^{2}$')\n",
    "    #plt.ylabel('DSC')\n",
    "    plt.title('T2w')\n",
    "    plt.subplot(143)\n",
    "    xy = np.vstack([areas_t1wce, dscs_t1wce])\n",
    "    z = gaussian_kde(xy)(xy)\n",
    "    plt.scatter(areas_t1wce, dscs_t1wce, c=z, s=50, edgecolors='k')\n",
    "    plt.xlabel('CA area, mm$^{2}$')\n",
    "    #plt.ylabel('DSC')\n",
    "    plt.title('T1w CE')\n",
    "    plt.subplot(144)\n",
    "    xy = np.vstack([areas_emc, dscs_emc])\n",
    "    z = gaussian_kde(xy)(xy)\n",
    "    plt.scatter(areas_emc, dscs_emc, c=z, s=50, edgecolors='k')\n",
    "    plt.xlabel('CA area, mm$^{2}$')\n",
    "    #plt.ylabel('DSC')\n",
    "    plt.title('T1w external')\n",
    "    plt.suptitle('nnUNet DSC with regards to CA area')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dice_area(scores_df_1, scores_df_2, scores_df_3, scores_df_4, \n",
    "                   dirname_gt_1, dirname_gt_2, dirname_gt_3, dirname_gt_4,\n",
    "                   dirname_1, dirname_2, dirname_3, dirname_4):\n",
    "    \n",
    "    areas_test, diameters_test, dscs_test = get_2Dscores(scores_df_1, dirname_gt_1, dirname_1)\n",
    "    areas_t2w, diameters_t2w, dscs_t2w = get_2Dscores(scores_df_2, dirname_gt_2, dirname_2)\n",
    "    areas_t1wce, diameters_t1wce, dscs_t1wce = get_2Dscores(scores_df_3, dirname_gt_3, dirname_3)\n",
    "    areas_emc, diameters_emc, dscs_emc = get_2Dscores(scores_df_4, dirname_gt_4, dirname_4)\n",
    "\n",
    "    bin_areas_test,bin_dscs_median_test,bin_dscs_low_test,bin_dscs_high_test = get_median_percentile_area_dice(areas_test, \n",
    "                                                                                                                  dscs_test)\n",
    "    bin_areas_t2w,bin_dscs_median_t2w,bin_dscs_low_t2w,bin_dscs_high_t2w = get_median_percentile_area_dice(areas_t2w, \n",
    "                                                                                                           dscs_t2w)\n",
    "    bin_areas_t1wce,bin_dscs_median_t1wce,bin_dscs_low_t1wce,bin_dscs_high_t1wce = get_median_percentile_area_dice(areas_t1wce,\n",
    "                                                                                                                   dscs_t1wce)\n",
    "    bin_areas_emc,bin_dscs_median_emc,bin_dscs_low_emc,bin_dscs_high_emc = get_median_percentile_area_dice(areas_emc, \n",
    "                                                                                                           dscs_emc, \n",
    "                                                                                                           bin_area_min = 0, \n",
    "                                                                                                           bin_area_max = 400, \n",
    "                                                                                                           bin_area_step = 50)\n",
    "\n",
    "    plt.figure(figsize=(17, 4))\n",
    "    plt.subplot(141)\n",
    "    p1 = plt.plot(bin_areas_test[1:], bin_dscs_median_test)\n",
    "    plt.fill_between(bin_areas_test[1:], bin_dscs_high_test, bin_dscs_low_test, alpha = 0.3)\n",
    "    plt.xlabel('CA area, mm$^{2}$')\n",
    "    plt.ylabel('DSC')\n",
    "    plt.title('T1w')\n",
    "    rect_ci = Rectangle((0,0), 0,0, alpha=0.3)\n",
    "    objects = [p1[0], rect_ci]\n",
    "    labels = ['Median', '90% CI']\n",
    "    plt.legend(objects, labels, loc='lower right')\n",
    "    plt.subplot(142)\n",
    "    plt.plot(bin_areas_t2w[1:], bin_dscs_median_t2w)\n",
    "    plt.fill_between(bin_areas_t2w[1:], bin_dscs_high_t2w, bin_dscs_low_t2w, alpha = 0.3)\n",
    "    plt.xlabel('CA area, mm$^{2}$')\n",
    "    #plt.ylabel('DSC')\n",
    "    plt.title('T2w')\n",
    "    plt.legend(objects, labels, loc='lower right')\n",
    "    plt.subplot(143)\n",
    "    plt.plot(bin_areas_t1wce[1:], bin_dscs_median_t1wce)\n",
    "    plt.fill_between(bin_areas_t1wce[1:], bin_dscs_high_t1wce, bin_dscs_low_t1wce, alpha = 0.3)\n",
    "    plt.xlabel('CA area, mm$^{2}$')\n",
    "    #plt.ylabel('DSC')\n",
    "    plt.title('T1w CE')\n",
    "    plt.legend(objects, labels, loc='lower right')\n",
    "    plt.subplot(144)\n",
    "    plt.plot(bin_areas_emc[1:], bin_dscs_median_emc)\n",
    "    plt.fill_between(bin_areas_emc[1:], bin_dscs_high_emc, bin_dscs_low_emc, alpha = 0.3)\n",
    "    plt.xlabel('CA area, mm$^{2}$')\n",
    "    #plt.ylabel('DSC')\n",
    "    plt.title('T1w external')\n",
    "    plt.legend(objects, labels, loc='lower right')\n",
    "    plt.suptitle('nnUNet DSC with regards to CA area')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dropout_dice(dirname_gt, dirname_do):\n",
    "    \n",
    "    sub_names = []\n",
    "\n",
    "    for item in os.listdir(dirname_gt):\n",
    "        sub_names.append(item[:-7])\n",
    "        \n",
    "        dscs_df = []\n",
    "\n",
    "    for sub_name in sub_names:\n",
    "\n",
    "        filenames_sub = glob.glob(dirname_do + sub_name + '*.nii.gz')\n",
    "        n = len(filenames_sub)\n",
    "\n",
    "        filename_gt = dirname_gt + sub_name + '.nii.gz'\n",
    "        gt_nii = nib.load(filename_gt)\n",
    "        gt = gt_nii.get_fdata()\n",
    "        dim = gt.shape\n",
    "\n",
    "        preds_array = np.zeros((dim[0], dim[1], dim[2], n), dtype = np.float32)\n",
    "        for i in range (0, n):\n",
    "            preds_array[..., i] = nib.load(filenames_sub[i]).get_fdata()\n",
    "\n",
    "        pred_mean = np.mean(preds_array, axis = 3)\n",
    "        dsc_mean = get_dice(gt, pred_mean)\n",
    "\n",
    "        dscs = []\n",
    "        for i in range (0, n):\n",
    "            dscs.append(get_dice(pred_mean, preds_array[..., i]))\n",
    "        dsc_ws = np.mean(dscs)\n",
    "\n",
    "        rec = {'sub': sub_name, 'dsc_mean': dsc_mean, 'dsc_ws': dsc_ws}\n",
    "        dscs_df.append(rec)\n",
    "\n",
    "    dscs_df = pd.DataFrame(dscs_df)\n",
    "\n",
    "    print (np.mean(dscs_df['dsc_ws']))\n",
    "    \n",
    "    #plt.plot((0.5, 1.0), (0.5, 1.0), ':k')\n",
    "    plt.ylim(0.0, 1.0)\n",
    "    plt.xlim(0.0, 1.0)\n",
    "    plt.plot((0, 1), (0, 1), color='w', alpha = 0)\n",
    "    plt.scatter(dscs_df['dsc_ws'], dscs_df['dsc_mean'], c = 'yellow', edgecolors = 'navy', s = 50)\n",
    "    plt.xlabel('DSC within samples')\n",
    "    plt.ylabel('DSC mean')\n",
    "    plt.axis('square')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bland_altman_plot(x_1, x_2, unit):\n",
    "    \n",
    "    x_1 = np.asarray(x_1)\n",
    "    x_2 = np.asarray(x_2)\n",
    "    mean = np.mean([x_1, x_2], axis=0)\n",
    "    diff = x_1 - x_2                   \n",
    "    md = np.mean(diff)                  \n",
    "    sd = np.std(diff, axis=0) \n",
    "\n",
    "    plt.scatter(mean, diff, edgecolor=\"navy\")\n",
    "    plt.axhline(md, color='gray', linestyle='-', label='MD: '+str(round(md, 2)))\n",
    "    plt.axhline(md + 1.96*sd, color='gray', linestyle='--', label='MD + 1.96SD: '+str(round(md + 1.96*sd, 2)))\n",
    "    plt.axhline(md - 1.96*sd, color='gray', linestyle='--', label='MD - 1.96SD: '+str(round(md - 1.96*sd, 2)))\n",
    "    plt.legend(loc = 'lower right', framealpha=0)\n",
    "    plt.xlabel('Average, ' + unit)\n",
    "    plt.ylabel('Difference, ' + unit)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ba(df_1, df_2, df_3, df_4):\n",
    "    \n",
    "    plt.figure(figsize=(16, 4))\n",
    "\n",
    "    plt.subplot(141)\n",
    "    bland_altman_plot(df_1['volume_gt']/1000, df_1['volume_pred']/1000, 'cm3')\n",
    "    plt.title('T1w')\n",
    "\n",
    "    plt.subplot(142)\n",
    "    bland_altman_plot(df_2['volume_gt']/1000, df_2['volume_pred']/1000, 'cm3')\n",
    "    plt.title('T2w')\n",
    "    plt.ylabel('')\n",
    "\n",
    "    plt.subplot(143)\n",
    "    bland_altman_plot(df_3['volume_gt']/1000, df_3['volume_pred']/1000, 'cm3')\n",
    "    plt.title('T1w CE')\n",
    "    plt.ylabel('')\n",
    "\n",
    "    plt.subplot(144)\n",
    "    bland_altman_plot(df_4['volume_gt']/1000, df_4['volume_pred']/1000, 'cm3')\n",
    "    plt.title('T1w EMC')\n",
    "    plt.ylabel('')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
